\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{array}

\usepackage{float}

\geometry{margin=1in}


\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}

\title{SRSML24: STM Machine Learning Module}
\author{Steven R. Schofield}
\date{\today}

\begin{document}

\maketitle

\section*{Overview}
This module provides tools for machine learning analysis of scanning tunnelling microscopy (STM) data, including autoencoder models, clustering tools, and STM-specific preprocessing.

\section*{Getting the Code}
Clone the repository from GitHub:

\begin{verbatim}
git clone https://github.com/srschofield/SRSML24.git
\end{verbatim}

\section*{Installation}
It is recommended to create a clean Python environment using \texttt{conda}. The following steps assume you are working on a macOS system with Apple Silicon:

\begin{verbatim}
# create and activate environment
conda create --name srsml24 python=3.8 -y
conda activate srsml24

# install packages
pip install -r requirements-macos.txt
\end{verbatim}

\subsection*{Known Working Configuration}
This module has been tested and is known to work with the following configuration on macOS 15.0.1 (Apple Silicon, M3 Pro chip):
\begin{table}[H]
\centering
\begin{tabular}{ll}
\hline
\textbf{Package} & \textbf{Version} \\
\hline
\texttt{python} & 3.8 \\
\texttt{tensorflow-macos} & 2.13.0 \\
\texttt{tensorflow-metal} & 1.0.1 \\
\texttt{numpy} & 1.24.3 \\
\texttt{pandas} & 2.0.3 \\
\texttt{matplotlib} & 3.7.5 \\
\texttt{scikit-learn} & 1.3.2 \\
\texttt{scipy} & 1.10.1 \\
\texttt{opencv-python} & 4.11.0.86 \\
\texttt{Pillow} & 10.4.0 \\
\texttt{joblib} & 1.4.2 \\
\texttt{jupyter} & 1.1.1 \\
\texttt{ipykernel} & 6.29.5 \\
\texttt{keras-core} & 0.1.5 \\
\texttt{spiepy} & 0.2.1 \\
\texttt{access2thematrix} & 0.4.4 \\
\hline
\end{tabular}
\caption{Verified package versions for macOS (Apple Silicon) environment}
\end{table}


These packages can be installed using the \texttt{requirements-macos.txt} file. The Python version is critical: other versions may cause compatibility issues with TensorFlow or other packages on Apple Silicon.

\section*{Python Files}
\begin{itemize}
  \item \texttt{data\_prep.py} – Functions for data preparation, including slicing STM images into windows and saving them in efficient formats.
  \item \texttt{model.py} – Defines convolutional autoencoder and UNET-style models.
  \item \texttt{utils.py} – Utility functions for loading/saving models, feature arrays, and results.
\end{itemize}

\section*{License}
This work is licensed under the \href{https://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)}. You may share and adapt the material for non-commercial purposes, provided that appropriate credit is given and any derivatives are licensed under identical terms.

\pagebreak
\section*{Parameter Summary}

\begin{longtable}{L{0.3\textwidth} L{0.65\textwidth}}
\textbf{Parameter} & \textbf{Description} \\
\hline
\endfirsthead

\textbf{Parameter} & \textbf{Description} \\
\hline
\endhead

\multicolumn{2}{l}{\textbf{General}} \\
\texttt{job\_name} & Label for the run, it will be the folder name for output. \\
\texttt{verbose} & If \texttt{True}, enables more detailed print output. \\

\hline
\multicolumn{2}{l}{\textbf{Matrix data file processing}} \\ 
\texttt{flatten\_method} & Method used to flatten STM images before analysis. Options are `none', `iterate\_mask', `poly\_xy'.\\
\texttt{pixel\_density} & All images will be converted to this pixel density (px/nm). \\
\texttt{pixel\_ratio} & Images that have ratio of fast/slow scan direction less than this will be discared. Setting to 1 means only complete (square) images are kept.\\
\texttt{data\_scaling} & Multiplicative factor for z-height data. Setting to 1.e9 means that the range 0--1 (used for training) corresponds to 1 nm.\\

\hline
\multicolumn{2}{l}{\textbf{Window generation}} \\ 
\texttt{window\_size} & Side length of square image windows (in pixels). \\
\texttt{window\_pitch} & Spacing between adjacent windows during tiling. \\

\hline
\multicolumn{2}{l}{\textbf{Data saving}} \\

\multicolumn{2}{l}{(Should remain defaults but options can be useful for examining data manually.)}\\
\texttt{save\_windows} & If \texttt{True}, saves image windows as \texttt{.npy} files (True).\\
\texttt{together} & If \texttt{True}, saves windows per image in a single file (True). \\
\texttt{save\_jpg} & If \texttt{True}, saves full STM images as JPGs (False).\\ 
\texttt{collate} & If \texttt{True}, flattens directory structure into one folder. (False). \\
\texttt{save\_window\_jpgs} & If \texttt{True}, saves image windows as JPGs. (False)\\

\hline
\multicolumn{2}{l}{\textbf{Autoencoder}} \\ 
\texttt{model\_name} & Label used to save and load the trained autoencoder model. \\
\texttt{batch\_size} & Number of windows per training batch. \\
\texttt{buffer\_size} & Size of shuffle buffer. \\
\texttt{learning\_rate} & Learning rate for the optimizer. \\
\texttt{epochs} & Number of training epochs. \\

\hline
\multicolumn{2}{l}{\textbf{Clustering}} \\ 
\texttt{cluster\_model\_name} & Name used when saving the clustering model. \\
\texttt{cluster\_batch\_size} & Number of latent vectors per clustering batch. \\
\texttt{cluster\_buffer\_size} & Size of buffer for clustering shuffle. \\
\texttt{num\_clusters} & Number of clusters to form using KMeans. \\
\texttt{n\_init} & Number of initializations for KMeans. \\
\texttt{max\_iter} & Max iterations for KMeans convergence. \\
\texttt{reassignment\_ratio} & Fraction of centroids reassigned each step. \\

\hline
\multicolumn{2}{l}{\textbf{Image prediction}} \\ 
\texttt{predict\_window\_pitch} & Window spacing during prediction step. \\
\texttt{mtrx\_train\_data\_limit} & Max number of training MTRX files to use. \\
\texttt{mtrx\_test\_data\_limit} & Max number of validation MTRX files to use. \\
\texttt{train\_data\_limit} & Limit on number of training windows. \\
\texttt{test\_data\_limit} & Limit on number of validation windows. \\
\end{longtable}

\pagebreak

\section*{Step 1: Converting MATRIX STM Data Files}

The initial step in utilizing the SRSML24 module involves converting raw STM data files from the Scienta Omicron MATRIX format into a standardized format suitable for machine learning analysis. This is accomplished using the \texttt{process\_mtrx\_files} function.

\subsection*{Function Overview}

\texttt{process\_mtrx\_files(mtrx\_paths, save\_data\_path, **kwargs)} is designed to batch process a list of MATRIX (\texttt{.mtrx}) files, performing the following operations:

\begin{itemize}
  \item \textbf{Loading Data:} Reads each \texttt{.mtrx} file and extracts image data along with associated metadata.
  \item \textbf{Preprocessing:} Applies flattening methods to correct for background variations and rescales images to a consistent pixel density.
  \item \textbf{Window Extraction:} Divides images into smaller windows of specified size and pitch, facilitating training of machine learning models.
  \item \textbf{Saving Outputs:} Stores processed windows and optional JPEG representations in a structured directory hierarchy under \texttt{save\_data\_path}.
\end{itemize}

This function ensures that STM data is preprocessed consistently, facilitating reliable training and evaluation of machine learning models within the SRSML24 framework. It will create a new directory called ``windows'' and subfolders under that with the names corresponding to the folders the matrix data was stored in (e.g., ``training'' or ``testing''). Unless the ``collate'' variable is set, the windowed data will retain the full directory structure (dates, days, etc) of the matrix data. The individual windows for a given folder of matrix data are all stored within a single .npy file, rather than separate .npy files for each window, since this is much more efficient for data saving and retrieving. Two text files are also saved, one has the meta data (STM bias voltage, current, etc.). The other has the coordinates for each window in the dataset. This is useful since these are not uniform at two edges of the original image for the general case where the full image is not perfectly divided by the dimensions of the individual windows. 

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_none}
\hspace{1em}\includegraphics[width=0.4\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_poly_xy}
\caption{Typical scanning tunnelling microscopy (STM) image. (Left) raw data. (Right) After poly\_xy background subtraction.}
\label{fig:stm}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00032}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00033}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00034}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00035}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00036}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00037}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00038}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00039}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00040}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00041}
\hspace{0.2em}
\includegraphics[width=0.07\textwidth]{figs/default_2011Jan07-144939_STM-STM_Spectroscopy--1_1_BD_00042}
\caption{A sequence of $30\times30$ pixel windows extracted from the STM image in Fig.~\ref{fig:stm} with an 8 pixel pitch.}
\end{figure}

\section*{Step 2: Preparing Datasets and Training the Autoencoder}

With windowed STM data in place, the next stage is to set up efficient TensorFlow data pipelines and train a convolutional autoencoder. This step handles the full model lifecycle, from data loading and batching to model training and saving the model and training history. These tools are provided by \texttt{model.py}, which we import as \texttt{m}, i.e., \texttt{import SRSML24.model as m}.

\subsection*{Preparing Datasets with \texttt{tf.data}}

To begin, window data stored as \texttt{.npy} files in \texttt{windows\_train\_path} and \texttt{windows\_test\_path} are listed. If it possible to choose a truncated subset of this list, e.g., to train on less data while optimising; this is done by setting the \texttt{train\_data\_limit} and \texttt{test\_data\_limit} parameters. These files are then loaded into TensorFlow \texttt{Dataset} objects for training and validation.

The function \texttt{m.create\_tf\_dataset\_batched(file\_paths, batch\_size, buffer\_size, window\_size, is\_autoencoder, shuffle)} constructs a pipeline that:

\begin{itemize}
  \item \textbf{Loads image batches:} Reads window data from \texttt{.npy} files located at the specified paths.
  \item \textbf{Shuffles window order:} When \texttt{shuffle=True}, randomizes input order to enhance model generalization.
  \item \textbf{Batches the data:} Groups windows into batches of size \texttt{batch\_size}.
  \item \textbf{Prefetches data:} Uses \texttt{prefetch(buffer\_size)} to improve throughput by overlapping data preparation with model training.
  \item \textbf{Pairs inputs and targets:} For autoencoder training, each window is used as both the input and target.
\end{itemize}

\subsection*{Model Building and Training}

Once the datasets are ready, the autoencoder can be constructed, compiled, and trained using the following workflow:

\begin{itemize}
  \item \textbf{Model instantiation:} 
    \begin{itemize}
      \item Use \texttt{m.build\_autoencoder(window\_size, model\_name)} to define the encoder–decoder architecture.
      \item Call \texttt{model.summary()} to inspect the model structure.
    \end{itemize}
  \item \textbf{Optimizer selection:}
    \begin{itemize}
      \item On Apple Silicon/macOS systems, use \texttt{tf.keras.optimizers.legacy.RMSprop} for TensorFlow-metal compatibility.
      \item On other systems, use the standard \texttt{tf.keras.optimizers.RMSprop}.
    \end{itemize}
  \item \textbf{Compilation:} Compile the model with:
    \begin{itemize}
      \item \texttt{loss='mean\_squared\_error'}
      \item Metrics: \texttt{['mse', 'mae']}
      \item Learning rate: from the \texttt{learning\_rate} parameter.
    \end{itemize}
  \item \textbf{Training:} Fit the model using:
    \begin{itemize}
      \item \texttt{train\_dataset} with \texttt{shuffle=True}
      \item \texttt{validation\_data=test\_dataset}
      \item The number of \texttt{epochs}
    \end{itemize}
  \item \textbf{Saving outputs and diagnostics:}
    \begin{itemize}
      \item Save the trained model using \texttt{m.save\_model(..., model\_train\_time)}.
      \item Plot and save the training history with \texttt{m.plot\_history\_from\_file(...)}, \texttt{m.save\_history(...)}.
    \end{itemize}
\end{itemize}

This produces a trained autoencoder model along with detailed training logs and performance plots, ready for use in clustering or anomaly detection tasks.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figs/autoencoder_summary}
\caption{Example UNET autoencoder model summary.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figs/unet_history}
\caption{Example plot of training history.}
\end{figure}




\section*{Step 3: Extracting Latent Features and Clustering}

Once the autoencoder has been trained, the next step is to extract compressed latent representations from its encoder and apply clustering to identify recurring patterns in the STM image windows. This step uses memory-efficient TensorFlow pipelines and supports large-scale datasets by processing in batches and saving intermediate results to disk.

\subsection*{Extracting Latent Features and Saving to Disk}

The encoder is applied to the training dataset to compute latent vectors for each image window. These are saved to disk in a structured format using:

\begin{verbatim}
m.extract_latent_features_to_disk_from_prebatched_windows(
    autoencoder_model, 
    train_dataset, 
    latent_features_path, 
    features_name='latent_features_train',
    return_array=False,
    verbose=False)
\end{verbatim}

This function stores the latent features in \texttt{.npy} files under \texttt{latent\_features\_path}, with names beginning with \texttt{latent\_features\_train}. Saving in batches avoids memory bottlenecks. The saved latent features are later used for training a cluster model.

\subsection*{Preparing the Latent Feature Dataset}

The saved latent feature files are listed and loaded into a TensorFlow data pipeline, ready for clustering:

\begin{verbatim}
latent_features_files, num_latent_files = dp.list_files_by_extension(
    latent_features_path, 'npy')

latent_features_dataset = m.create_latent_features_tf_dataset(
    latent_features_files,
    batch_size=cluster_batch_size,
    shuffle=True, 
    shuffle_buffer_size=cluster_buffer_size)
\end{verbatim}

\subsection*{Clustering with MiniBatch KMeans}

Clustering is performed using the MiniBatch KMeans algorithm, which is scalable to large datasets and performs incremental updates to the centroids:

\begin{verbatim}
cluster_model, convergence_history = m.train_kmeans(
    latent_features_dataset,
    batch_size=cluster_batch_size,
    num_clusters=num_clusters,
    n_init=n_init,
    max_iter=max_iter,
    reassignment_ratio=reassignment_ratio)
\end{verbatim}

The training history includes convergence diagnostics and can be plotted to assess stability across epochs.

\subsection*{Saving the Clustering Model}

The trained clustering model is saved using:

\begin{verbatim}
m.save_cluster_model(cluster_model, cluster_model_path, model_name=cluster_model_name)
\end{verbatim}

This ensures that cluster labels can be reused for prediction, visualization, or interpretation in downstream analysis.

\subsection*{Outputs}

This step produces the following key results:

\begin{itemize}
  \item \textbf{Latent feature vectors:} Encoded representations saved as batched \texttt{.npy} files.
  \item \textbf{Trained KMeans model:} Saved clustering model for reuse or deployment.
  \item \textbf{Convergence history:} Optional diagnostics on clustering stability and progress.
\end{itemize}

\begin{figure}[H]
\centering
%\includegraphics[width=0.85\textwidth]{figs/kmeans_clusters}
\caption{Cluster assignments in latent space using MiniBatch KMeans. Each color represents a distinct pattern or feature set discovered from STM data.}
\end{figure}


\section*{Step 4: Making Cluster Predictions on New STM Images}

In the final step, trained models are applied to new STM image data. This allows the latent features learned by the autoencoder, and the clustering patterns identified via KMeans, to be mapped onto previously unseen scans—highlighting recurring patterns, regions of interest, or anomalies.

\subsection*{Preparing Prediction Data}

STM images in the Scienta Omicron MATRIX format are first preprocessed into windowed image data using the same function as in Step 1:

\begin{verbatim}
dp.process_mtrx_files(
    mtrx_predict_file_list,
    job_data_path,
    flatten_method = flatten_method,
    pixel_density = pixel_density,
    pixel_ratio = pixel_ratio,
    data_scaling = data_scaling,
    window_size = window_size, 
    window_pitch = predict_window_pitch,
    save_windows = save_windows,
    save_window_jpgs = save_window_jpgs,
    save_jpg = save_jpg,
    together = together,
    collate = collate,
    verbose = verbose)
\end{verbatim}

The windows and coordinate files are saved in the same structure as the training set, enabling seamless integration with the trained models.

\subsection*{Loading Trained Models}

Both the autoencoder and clustering model are reloaded from disk:

\begin{verbatim}
autoencoder_model = m.load_model(model_path, model_name=model_name)
cluster_model = m.load_cluster_model(cluster_model_path, model_name=cluster_model_name)
\end{verbatim}

\subsection*{Cluster Prediction Workflow}

For each preprocessed STM image:

\begin{enumerate}
  \item \textbf{Window data and coordinates} are loaded from disk.
  \item A full image is reconstructed from the original window tiles.
  \item A TensorFlow data pipeline is built to pass the windows through the autoencoder.
  \item The autoencoder encoder generates latent features for each window.
  \item The clustering model assigns each window to a cluster.
  \item Cluster labels are mapped back to image coordinates and rendered as a cluster map.
  \item The result is optionally padded to match the original image dimensions.
  \item A side-by-side visualization of the raw and clustered image is saved to disk.
\end{enumerate}

This workflow is handled in the following loop:

\begin{verbatim}
for prediction_file, coords_file in zip(predict_data_files_list, image_windows_coordinates_file_list):
    ...
    predict_dataset = m.create_tf_dataset_batched(...)
    latent_features = m.extract_latent_features_to_disk_from_prebatched_windows(
        autoencoder_model, predict_dataset, '', return_array=True)
    cluster_predictions = cluster_model.predict(latent_features)
    cluster_img = dp.reconstruct_cluster_image(...)
    cluster_img = ut.pad_cluster_image(...)
    m.display_reconstructed_and_cluster_images(...)
\end{verbatim}

\subsection*{Output}

Each prediction run saves the following outputs in the \texttt{predictions\_path} folder:

\begin{itemize}
  \item \textbf{Cluster map:} A color-coded image showing predicted cluster labels for each image region.
  \item \textbf{Overlay (optional):} A composite image showing the raw STM image overlaid with transparency or color labels.
  \item \textbf{Reconstruction log:} Coordinate-based window reconstructions for reproducibility.
\end{itemize}

\begin{figure}[H]
\centering
%\includegraphics[width=0.45\textwidth]{figs/prediction_raw}
\hspace{1em}
%\includegraphics[width=0.45\textwidth]{figs/prediction_clusters}
\caption{Cluster prediction output. (Left) reconstructed raw STM image. (Right) predicted cluster labels, highlighting nanoscale structure.}
\end{figure}

This concludes the SRSML24 processing pipeline: from raw data preprocessing, through autoencoder training and latent-space clustering, to visualization of predictions on new STM images.


\end{document}
