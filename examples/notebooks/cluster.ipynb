{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # CNN autoencoder and Clustering from MTRX data\n",
    "\n",
    "Use this notebook to load Scienta Omicron Matrix format SPM data and create standardised images for machine learning training and analysis. The code can generate both JPG image data, useful for manually checking the data, and windowed numpy data that can be loaded into ML models. \n",
    "\n",
    "The notebook then creates an autoencoder for training on a large dataset, followed by KMEANS clustering. \n",
    "\n",
    "**Author**: Steven R. Schofield  \n",
    "**Created**: November, 2024 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path = /hpc/srs/Python/modules\n",
      "data_path = /hpc/srs/Python-data\n"
     ]
    }
   ],
   "source": [
    "# Define path where to find the module. This allows for a different path depending on where the code is running (my mac or the cluster)\n",
    "import os\n",
    "\n",
    "module_path_list = [\n",
    "    '/Users/steven/academic-iCloud/Python/modules',\n",
    "    '/hpc/srs/Python/modules'\n",
    "] \n",
    "\n",
    "data_path_list = [\n",
    "    '/Users/steven/Python-data',\n",
    "    '/hpc/srs/Python-data'\n",
    "]\n",
    "\n",
    "module_path = next((p for p in module_path_list if os.path.exists(p)), None)\n",
    "if not module_path:\n",
    "    exit(\"No valid module paths.\")\n",
    "else:\n",
    "    print('module_path = {}'.format(module_path))\n",
    "\n",
    "data_path = next((p for p in data_path_list if os.path.exists(p)), None)\n",
    "if not module_path:\n",
    "    exit(\"No valid data paths.\")\n",
    "else:\n",
    "    print('data_path = {}'.format(data_path))\n",
    "\n",
    "# adjust tensorflow output level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 0 default all messages, 1 warnings and errors, 2, errors, 3 fatal errors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version: 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:45:29) \n",
      "[GCC 10.4.0]\n",
      "TensorFlow version: 2.4.1\n",
      "TensorFlow is built with CUDA: True\n",
      "TensorFlow is built with ROCm: False\n",
      "\n",
      "System: Linux 4.18.0-513.24.1.el8_9.x86_64 (x86_64)\n",
      "Platform: Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28\n",
      "Processor: x86_64\n",
      "\n",
      "Number of GPUs available to TensorFlow: 1\n",
      "GPU Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "\n",
      ">>> Running with GPU available <<<  (Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28)\n",
      "\n",
      "Current time 2024-12-06 12:29:57\n"
     ]
    }
   ],
   "source": [
    "# # Ensure modules are reloaded \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "import platform\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Add custom module path to list\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Import custom module\n",
    "import SRSML24.data_prep as dp\n",
    "import SRSML24.model as m\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.optimizers.legacy import Adam \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import platform \n",
    "\n",
    "m.print_system_info()\n",
    "\n",
    "start_time = dp.current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for windows creation\n",
    "job_name = 'all_data_2023'\n",
    "job_data_path = dp.create_new_data_path(data_path, job_name, include_date=False)\n",
    "mtrx_train_path = os.path.join(data_path, 'mtrx/train')\n",
    "mtrx_test_path = os.path.join(data_path, 'mtrx/test')\n",
    "mtrx_predict_path = os.path.join(data_path, 'mtrx/predict')\n",
    "flatten_method = 'poly_xy'\n",
    "pixel_density = 15.0    # Convert all images to a constant pixel density\n",
    "pixel_ratio = 0.7       # If an image has less than this % in the slow scan direction it is discarded\n",
    "data_scaling = 1.e9     # Scale the z-height of the data\n",
    "window_size = 32        # Window size for training/validation\n",
    "window_pitch = 32       # Window pitch for training/validation\n",
    "together = True        # Set this True to save image windows for a mtrx image as a single file rather than separate files.\n",
    "collate = False         # Set this True to remove all subfolder directories and save all data in root data path\n",
    "\n",
    "# Parameters for training\n",
    "model_name = 'unet_' + job_name\n",
    "batch_size = 128\n",
    "buffer_size = 12800 # shuffling\n",
    "learning_rate = 1e-4\n",
    "epochs = 5\n",
    "\n",
    "# Parameters for clustering\n",
    "cluster_model_name = model_name + '_kmeans'\n",
    "cluster_batch_size = 5120 # This is the number of latent features in a batch for clustering. \n",
    "                          # Does not have to be the same as for training and probably should \n",
    "                          # be larger. \n",
    "cluster_buffer_size = cluster_batch_size * 5    # shuffling buffer\n",
    "num_clusters=20                                # Desired number of clusters (centroids) to form in the data.\n",
    "n_init=50                                       # Number of times the algorithm will run with different centroid seeds.\n",
    "max_iter=1000                                   # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "reassignment_ratio=0.05                         # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    "\n",
    "\n",
    "# Parameters for PREDICTIONS\n",
    "predict_window_pitch = 4               # Window pitch for prediction\n",
    "\n",
    "\n",
    "# DATA LIMITS FOR TESTING THE CODE\n",
    "mtrx_train_data_limit = None #500         # Number of MTRX files to process (training)\n",
    "mtrx_test_data_limit = None #100         # Number of MTRX files to process (validation)\n",
    "\n",
    "train_data_limit = None #2000*batch_size\n",
    "predict_data_limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: /hpc/srs/Python-data/all_data_2023/jpg\n",
      "Deleted: /hpc/srs/Python-data/all_data_2023/windows\n",
      "All specified folders have been successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "# REMOVE ALL DATA FOLDERS EXCEPT MTRX \n",
    "dp.delete_data_folders(job_data_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62592 files with extension 'Z_mtrx' in directory:\n",
      "/hpc/srs/Python-data/mtrx/train\n",
      "There are 55845 files to process\n",
      ".t.ttt.....t..t....tt.....t.......ttt......t...........................tt....tttt....t.....tt...... 100\n",
      "....t..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mtrx_train_file_list, _ \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39mlist_files_by_extension(mtrx_train_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ_mtrx\u001b[39m\u001b[38;5;124m'\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_mtrx_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmtrx_train_file_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6747\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# save data path\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflatten_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mflatten_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_density\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpixel_density\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpixel_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_scaling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_scaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_pitch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_pitch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_windows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_jpg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtogether\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtogether\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/modules/SRSML24/data_prep.py:307\u001b[0m, in \u001b[0;36mprocess_mtrx_files\u001b[0;34m(mtrx_paths, save_data_path, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m    \n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Process image\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_image_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Subtract image minimum and then scale.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m img \u001b[38;5;241m=\u001b[39m (img \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(img)) \u001b[38;5;241m*\u001b[39m data_scaling\n",
      "File \u001b[0;32m~/Python/modules/SRSML24/data_prep.py:1076\u001b[0m, in \u001b[0;36mflatten_image_data\u001b[0;34m(img, flatten_method)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     img, mask, n \u001b[38;5;241m=\u001b[39m spiepy\u001b[38;5;241m.\u001b[39mflatten_by_iterate_mask(img)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m flatten_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoly_xy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1076\u001b[0m     img, _ \u001b[38;5;241m=\u001b[39m \u001b[43mspiepy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_poly_xy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m flatten_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1078\u001b[0m     img \u001b[38;5;241m=\u001b[39m flatten_by_row_mean(img)\n",
      "File \u001b[0;32m~/local/miniconda3/envs/tf/lib/python3.9/site-packages/spiepy/__init__.py:145\u001b[0m, in \u001b[0;36mflatten_poly_xy\u001b[0;34m(im_in, mask, deg)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_poly_xy\u001b[39m(im_in, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, deg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Performs a polynomial plane fit of order 'deg' using the method of\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    least squares.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m            Is the plane which has been subtracted from the image.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflatten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoly_xy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/local/miniconda3/envs/tf/lib/python3.9/site-packages/spiepy/flatten.py:145\u001b[0m, in \u001b[0;36mpoly_xy\u001b[0;34m(im_in, mask, deg)\u001b[0m\n\u001b[1;32m    143\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39marray(im, mask \u001b[38;5;241m=\u001b[39m mask)\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mcompressed()\n\u001b[1;32m    144\u001b[0m coef \u001b[38;5;241m=\u001b[39m _polyfit2d(x, y, z, order)\n\u001b[0;32m--> 145\u001b[0m im_plane \u001b[38;5;241m=\u001b[39m \u001b[43m_polyval2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m im \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m im_plane\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spiepy_image_structure:\n",
      "File \u001b[0;32m~/local/miniconda3/envs/tf/lib/python3.9/site-packages/spiepy/flatten.py:62\u001b[0m, in \u001b[0;36m_polyval2d\u001b[0;34m(x, y, m)\u001b[0m\n\u001b[1;32m     60\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(x)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, (i, j) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(m, ij):\n\u001b[0;32m---> 62\u001b[0m     z \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "mtrx_train_file_list, _ = dp.list_files_by_extension(mtrx_train_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_train_file_list[0:mtrx_train_data_limit],\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, window_pitch = window_pitch,\n",
    "    save_windows = True,\n",
    "    save_jpg = True,\n",
    "    together = together,\n",
    "    collate = collate,\n",
    "    verbose = False\n",
    "    )\n",
    "\n",
    "# Test data\n",
    "mtrx_test_file_list, _ = dp.list_files_by_extension(mtrx_test_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_test_file_list[0:mtrx_test_data_limit],\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, window_pitch = window_pitch,\n",
    "    save_windows = True,\n",
    "    save_jpg = True,\n",
    "    together = together,\n",
    "    collate = collate,\n",
    "    verbose = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Set up tensorflow data pipeline -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - tensorflow data pipeline for autoencoder\n",
    "windows_train_path = os.path.join(job_data_path, 'windows/train')\n",
    "train_files, num_train = dp.list_files_by_extension(windows_train_path, 'npy')\n",
    "train_files = train_files[:train_data_limit]\n",
    "# Create dataset with prefetching\n",
    "#train_dataset = m.create_tf_dataset(train_files, batch_size=batch_size, buffer_size=buffer_size, is_autoencoder=True, shuffle=True)\n",
    "train_dataset = m.create_tf_dataset_batched(\n",
    "    train_files, \n",
    "    batch_size=batch_size, \n",
    "    buffer_size=buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data - tensorflow data pipeline for autoencoder\n",
    "windows_test_path = os.path.join(job_data_path, 'windows/test')\n",
    "test_files, num_test = dp.list_files_by_extension(windows_test_path, 'npy')\n",
    "test_files = test_files[:train_data_limit]\n",
    "\n",
    "# Create dataset with prefetching\n",
    "test_dataset = m.create_tf_dataset_batched(\n",
    "    test_files, \n",
    "    batch_size=batch_size, \n",
    "    buffer_size=buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Autoencoder build and train -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the UNET model\n",
    "autoencoder_model = m.build_autoencoder(window_size=window_size,model_name=model_name)\n",
    "autoencoder_model.summary()\n",
    "\n",
    "# Check if running on Apple Silicon\n",
    "is_mac_silicon = platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n",
    "\n",
    "if is_mac_silicon:\n",
    "    print(\"Running on Mac with Apple Silicon. Using legacy RMSprop optimizer.\")\n",
    "    autoencoder_model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.RMSprop(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae']\n",
    "    )\n",
    "else:\n",
    "    print(\"Not running on Mac with Apple Silicon. Using new RMSprop optimizer.\")\n",
    "    autoencoder_model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the tf.data datasets\n",
    "history = autoencoder_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the model as soon as training completes\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "m.save_model(autoencoder_model, model_path, model_name=model_name)\n",
    "\n",
    "end_time = dp.current_datetime()\n",
    "dp.elapsed_time(start_time,end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "m.plot_training_history(history, \n",
    "                        loss_name='loss', \n",
    "                        val_loss_name='val_loss', \n",
    "                        metric_names=['mse', 'mae'], \n",
    "                        save_to_disk=True,\n",
    "                        val_metric_names=['val_mse', 'val_mae'],\n",
    "                        output_path=model_path,\n",
    "                        dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Extract latent features using autoencoder model\n",
    "Will save the latent features also to disk so this step needs to run only once for a given set of parameters -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.delete_data_folders(\n",
    "    job_data_path, \n",
    "    subdirectories='latent_features',\n",
    "    override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - tensorflow data pipeline \n",
    "windows_train_path = os.path.join(job_data_path, 'windows/train')\n",
    "train_files, num_train = dp.list_files_by_extension(windows_train_path, 'npy')\n",
    "train_files = train_files[:train_data_limit]\n",
    "\n",
    "train_dataset = m.create_tf_dataset_batched(\n",
    "    train_files, \n",
    "    batch_size=cluster_batch_size, \n",
    "    buffer_size=cluster_buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained autoencoder model\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save latent features to disk\n",
    "latent_features_path = os.path.join(job_data_path, 'latent_features')\n",
    "\n",
    "m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "    autoencoder_model, \n",
    "    train_dataset, \n",
    "    latent_features_path, \n",
    "    features_name='latent_features_train',\n",
    "    return_array=False,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Create tensorflow dataset pipeline for latent features -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and sort latent feature files\n",
    "latent_features_path = os.path.join(job_data_path, 'latent_features')\n",
    "latent_features_files, num_latent_files = dp.list_files_by_extension(latent_features_path, 'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latent features from disk into a tensor dataset pipeline\n",
    "latent_features_dataset = m.create_latent_features_tf_dataset(\n",
    "    latent_features_files,\n",
    "    batch_size=cluster_batch_size,\n",
    "    shuffle=True, \n",
    "    shuffle_buffer_size=cluster_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Train KMEANS cluster model -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model, convergence_history = m.train_kmeans(\n",
    "    latent_features_dataset,                # tf.data.Dataset containing batches of latent feature vectors.\n",
    "    batch_size=cluster_batch_size,          # Size of each batch for the KMeans model (controls memory usage and stability).\n",
    "    num_clusters=num_clusters,              # Desired number of clusters (centroids) to form in the data.\n",
    "    n_init=n_init,                          # Number of times the algorithm will run with different centroid seeds.\n",
    "    max_iter=max_iter,                      # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "    reassignment_ratio=reassignment_ratio   # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    ")\n",
    "\n",
    "# Save cluster model\n",
    "cluster_model_path = os.path.join(job_data_path,'cluster_model')\n",
    "m.save_cluster_model(cluster_model, cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Process Predictions MTRX data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.delete_data_folders(\n",
    "    job_data_path, \n",
    "    subdirectories='jpg',\n",
    "    override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data\n",
    "mtrx_predict_file_list, _ = dp.list_files_by_extension(mtrx_predict_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "data_scaling = 1.e9     # Scale the z-height of the data\n",
    "\n",
    "flatten_method = 'row_and_poly_xy_deg_2'\n",
    "flatten_method = 'row_mean'\n",
    "flatten_method = 'iterate_mask'\n",
    "flatten_method = 'poly_xy'\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_predict_file_list,\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, window_pitch = predict_window_pitch,\n",
    "    save_windows = True,\n",
    "    save_jpg = True,\n",
    "    collate = False,\n",
    "    verbose = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Make data predictions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained autoencoder\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)\n",
    "\n",
    "# Load a previously saved cluster model from disk\n",
    "cluster_model_path = os.path.join(job_data_path,'cluster_model')\n",
    "cluster_model = m.load_cluster_model(cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of folders containing predict window data\n",
    "windows_predict_path = os.path.join(job_data_path, 'windows/predict')\n",
    "predict_data_files_list = dp. find_bottom_layer_folders(windows_predict_path)\n",
    "predict_data_files_list = predict_data_files_list[:predict_data_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "for dir in predict_data_files_list:\n",
    "    #Limit viewing to FU images\n",
    "    if not dir.endswith(\"FU\"):\n",
    "        print('Not FU so skipping: {}'.format(dir))\n",
    "        continue  \n",
    "\n",
    "    # get list of the individual file names of the windows\n",
    "    window_list, num_windows = dp.list_files_by_extension(dir, extension=\".npy\", verbose=False)\n",
    "    # load the numpy windows\n",
    "    image_windows = dp.load_n_numpy_files(window_list,num_windows)\n",
    "    # load the coordinate files for the windows for window reconstruction\n",
    "    image_windows_coordinates = dp.load_coordinates_file(dir)\n",
    "    # Build the reconstruction of the original image\n",
    "    reconstructed_img = dp.reconstruct_image(image_windows,image_windows_coordinates,window_size)\n",
    "\n",
    "    # create a tf dataset from the numpy windows for making the latent features\n",
    "    predict_dataset = m.create_tf_dataset(window_list, batch_size=num_windows, buffer_size=num_windows, shuffle=False, is_autoencoder=False)\n",
    "    # make the latent features for each window using the autoencoder model \n",
    "    latent_predict_features, num_latent_predictions = m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "        autoencoder_model, \n",
    "        predict_dataset, \n",
    "        latent_features_path, \n",
    "        features_name='latent_features_train',\n",
    "        return_array=True,\n",
    "        verbose=False)\n",
    "    # make preductions \n",
    "    cluster_predictions = cluster_model.predict(latent_predict_features)\n",
    "    # Build the reconstruction of the predicted cluster label data\n",
    "    cluster_img = dp.reconstruct_cluster_image(image_windows_coordinates,window_size, cluster_predictions)\n",
    "    image_name = os.path.basename(dir)\n",
    "    # Path to save latent features to disk\n",
    "    predictions_path = os.path.join(job_data_path, 'predictions')\n",
    "    m.display_reconstructed_and_cluster_images(reconstructed_img,cluster_img,show_overlay=True,\n",
    "                                                save_to_disk=True,\n",
    "                                                predictions_time_stamp=predictions_time_stamp,\n",
    "                                                output_path=job_data_path,\n",
    "                                                image_name=image_name,\n",
    "                                                dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
