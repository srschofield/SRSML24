{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # CNN autoencoder and Clustering from MTRX data\n",
    "\n",
    "Use this notebook to load Scienta Omicron Matrix format SPM data and create standardised images for machine learning training and analysis. The code can generate both JPG image data, useful for manually checking the data, and windowed numpy data that can be loaded into ML models. \n",
    "\n",
    "The notebook then creates an autoencoder for training on a large dataset, followed by KMEANS clustering. \n",
    "\n",
    "**Author**: Steven R. Schofield  \n",
    "**Created**: November, 2024 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning autoencoder + Kmeans for STM image data analysis\n",
    "## Steven R. Schofield (Universtiy College London Dec. 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path = /Users/steven/academic-iCloud/Python/modules\n",
      "data_path = /Users/steven/Python-data\n"
     ]
    }
   ],
   "source": [
    "# Define path where to find the module. This allows for a different path depending on where the code is running (my mac or the cluster)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Define candidate paths\n",
    "module_path_list = [\n",
    "    '/Users/steven/academic-iCloud/Python/modules',\n",
    "    '/hpc/srs/Python/modules'\n",
    "]\n",
    "\n",
    "data_path_list = [\n",
    "    '/Users/steven/Python-data',\n",
    "    '/hpc/srs/Python-data'\n",
    "]\n",
    "\n",
    "# Resolve actual paths\n",
    "module_path = next((p for p in module_path_list if os.path.exists(p)), None)\n",
    "data_path = next((p for p in data_path_list if os.path.exists(p)), None)\n",
    "\n",
    "# Check and report missing paths\n",
    "if module_path is None:\n",
    "    print(\"Error: Could not locate a valid module path.\")\n",
    "if data_path is None:\n",
    "    print(\"Error: Could not locate a valid data path.\")\n",
    "\n",
    "if module_path is None or data_path is None:\n",
    "    sys.exit(1)\n",
    "\n",
    "# Print resolved paths\n",
    "print(f\"module_path = {module_path}\")\n",
    "print(f\"data_path = {data_path}\")\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version: 3.8.18 (default, Sep 11 2023, 08:17:16) \n",
      "[Clang 14.0.6 ]\n",
      "TensorFlow version: 2.13.0\n",
      "TensorFlow is built with CUDA: False\n",
      "TensorFlow is built with ROCm: False\n",
      "\n",
      "System: Darwin 24.3.0 (arm64)\n",
      "Platform: macOS-15.3.2-arm64-arm-64bit\n",
      "Processor: arm\n",
      "\n",
      "Number of GPUs available to TensorFlow: 1\n",
      "GPU Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "\n",
      ">>> Running with GPU available <<<  (macOS-15.3.2-arm64-arm-64bit)\n",
      "\n",
      "Current time 2025-04-19 23:00:53\n"
     ]
    }
   ],
   "source": [
    "# # Ensure modules are reloaded \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard modules\n",
    "import numpy as np\n",
    "\n",
    "import platform\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Add custom module path to list\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Import custom module\n",
    "import SRSML24.data_prep as dp\n",
    "import SRSML24.model as m\n",
    "import SRSML24.utils as ut\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.optimizers.legacy import Adam \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import platform \n",
    "\n",
    "m.print_system_info()\n",
    "\n",
    "start_time = dp.current_datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programme variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for windows creation\n",
    "# General\n",
    "job_name = 'Summer_2025_Adam_all'\n",
    "verbose = False             # Set this True to print out more information\n",
    "\n",
    "# MTRX preprocessing\n",
    "flatten_method = 'poly_xy'\n",
    "pixel_density = 15.0        # Convert all images to a constant pixel density\n",
    "pixel_ratio = 0.7           # If an image has less than this % in the slow scan direction it is discarded\n",
    "data_scaling = 1.e9         # Scale the z-height of the data\n",
    "\n",
    "# Windowing\n",
    "window_size = 16            # Window size for training/validation\n",
    "window_pitch = 8            # Window pitch for training/validation\n",
    "\n",
    "# Data saving options\n",
    "save_windows = True         # Save the windows as numpy files\n",
    "together = True             # Set this True to save image windows for a mtrx image as a single file rather than separate files.\n",
    "save_jpg = False            # Save the full image as a jpg\n",
    "collate = False             # Set this True to remove all subfolder directories and save all data in root data path\n",
    "save_window_jpgs = False    # Save the windows as jpgs for inspection\n",
    "\n",
    "# Parameters for training\n",
    "model_name = 'unet_' + job_name\n",
    "batch_size = 128\n",
    "buffer_size = 12800 # shuffling\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "# Parameters for clustering\n",
    "cluster_model_name = model_name + '_kmeans'\n",
    "cluster_batch_size = 5120 # This is the number of latent features in a batch for clustering. \n",
    "                          # Does not have to be the same as for training and probably should \n",
    "                          # be larger. \n",
    "cluster_buffer_size = cluster_batch_size * 5    # shuffling buffer\n",
    "num_clusters=20                                 # Desired number of clusters (centroids) to form in the data.\n",
    "n_init=50                                       # Number of times the algorithm will run with different centroid seeds.\n",
    "max_iter=1000                                   # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "reassignment_ratio=0.05                         # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    "\n",
    "# Parameters for PREDICTIONS\n",
    "predict_window_pitch = 1                        # Window pitch for prediction\n",
    "\n",
    "# DATA LIMITS FOR TESTING THE CODE\n",
    "mtrx_train_data_limit = 1000 #None                    # Number of MTRX files to process (training)\n",
    "mtrx_test_data_limit = 200 #None                     # Number of MTRX files to process (validation)\n",
    "\n",
    "train_data_limit = None                         # Limit the data used in the autoencoder training\n",
    "test_data_limit = None                          # Limit the data used in the autoencoder training (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data_path = dp.create_new_data_path(data_path, job_name, include_date=False)\n",
    "\n",
    "mtrx_train_path = os.path.join(data_path, 'mtrx/train')\n",
    "mtrx_test_path = os.path.join(data_path, 'mtrx/test')\n",
    "mtrx_predict_path = os.path.join(data_path, 'mtrx/predict')\n",
    "\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "cluster_model_path = os.path.join(job_data_path,'cluster_model')\n",
    "\n",
    "latent_features_path = os.path.join(job_data_path, 'latent_features')\n",
    "predict_latent_features_path = os.path.join(job_data_path, 'latent_features_predictions')\n",
    "\n",
    "windows_train_path = os.path.join(job_data_path, 'windows/train')\n",
    "windows_test_path = os.path.join(job_data_path, 'windows/test')\n",
    "windows_predict_path = os.path.join(job_data_path, 'windows/predict')\n",
    "\n",
    "predictions_path = os.path.join(job_data_path, f'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Matrix format data to windows for autoencoder training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No target folders found to delete.\n"
     ]
    }
   ],
   "source": [
    "# REMOVE ALL DATA FOLDERS EXCEPT MTRX \n",
    "dp.delete_data_folders(job_data_path, subdirectories=[\"jpg\", \"windows\", \"windows-jpg\"], override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1973 files with extension 'Z_mtrx' in directory:\n",
      "/Users/steven/Python-data/mtrx/train\n",
      "There are 1000 files to process\n",
      "....t...t....t....................t.t............ttt.......t.......t.....ttt.t............tt..tttt. 100\n",
      "t........t......ttt..t..tt.ttt.........t..t....tt.t.tt..tt...tttttttttttttttttttttt.ttt.ttt.tt..ttt 200\n",
      "\btt..t..tttt...tt.tttt.t.t.tttttttt.t.tt.tt.t..t.tt..t.......t.t....ttt...........ttt........t...t... 300\n",
      "t....t.............t...............tt..................t........t."
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "mtrx_train_file_list, _ = dp.list_files_by_extension(mtrx_train_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_train_file_list[0:mtrx_train_data_limit],\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, window_pitch = window_pitch,\n",
    "    save_windows = save_windows,\n",
    "    save_window_jpgs=save_window_jpgs,\n",
    "    save_jpg = save_jpg,\n",
    "    together = together,\n",
    "    collate = collate,\n",
    "    verbose = verbose\n",
    "    )\n",
    "\n",
    "# Test data\n",
    "mtrx_test_file_list, _ = dp.list_files_by_extension(mtrx_test_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_test_file_list[0:mtrx_test_data_limit],\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, window_pitch = window_pitch,\n",
    "    save_windows = save_windows,\n",
    "    save_window_jpgs=save_window_jpgs,\n",
    "    save_jpg = save_jpg,\n",
    "    together = together,\n",
    "    collate = collate,\n",
    "    verbose = verbose\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build tensorflow data pipeline for training and validation of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - tensorflow data pipeline for autoencoder\n",
    "train_files, num_train = dp.list_files_by_extension(windows_train_path, 'npy')\n",
    "train_files = train_files[:train_data_limit]\n",
    "\n",
    "# Create dataset with prefetching\n",
    "train_dataset = m.create_tf_dataset_batched(\n",
    "    train_files, \n",
    "    batch_size=batch_size, \n",
    "    buffer_size=buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)\n",
    "\n",
    "# Validation data - tensorflow data pipeline for autoencoder\n",
    "test_files, num_test = dp.list_files_by_extension(windows_test_path, 'npy')\n",
    "test_files = test_files[:test_data_limit]\n",
    "\n",
    "# Create dataset with prefetching\n",
    "test_dataset = m.create_tf_dataset_batched(\n",
    "    test_files, \n",
    "    batch_size=batch_size, \n",
    "    buffer_size=buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the UNET model\n",
    "autoencoder_model = m.build_autoencoder(window_size=window_size,model_name=model_name)\n",
    "autoencoder_model.summary()\n",
    "\n",
    "# Check if running on Apple Silicon\n",
    "is_mac_silicon = platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n",
    "\n",
    "if is_mac_silicon:\n",
    "    print(\"Detected Mac with Apple Silicon. Compiling the model with the legacy RMSprop optimizer for compatibility with TensorFlow-metal.\")\n",
    "    autoencoder_model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.RMSprop(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae']\n",
    "    )\n",
    "else:\n",
    "    print(\"Compiling the model with the RMSprop optimizer.\")\n",
    "    autoencoder_model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the tf.data datasets\n",
    "history = autoencoder_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "model_train_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(f\"Model training completed at {model_train_time}\")\n",
    "\n",
    "# Save the model as soon as training completes\n",
    "m.save_model(autoencoder_model, model_path, model_name=model_name, model_train_time=model_train_time)\n",
    "\n",
    "end_time = dp.current_datetime()\n",
    "dp.elapsed_time(start_time,end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_data_file_path = m.save_history(history, model_path=model_path, model_name=model_name, model_train_time=model_train_time)\n",
    "#history_data_file_path=model_path+'/'+model_name+'_'+model_train_time+'_history_data.dat'\n",
    "m.plot_history_from_file(file_path=history_data_file_path,\n",
    "                            loss_name='loss', \n",
    "                            val_loss_name='val_loss', \n",
    "                            metric_names=['mse', 'mae'], \n",
    "                            val_metric_names=['val_mse', 'val_mae'],\n",
    "                            dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Latent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.delete_data_folders(\n",
    "    job_data_path, \n",
    "    subdirectories='latent_features',\n",
    "    override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained autoencoder model\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - tensorflow data pipeline \n",
    "train_files, num_train = dp.list_files_by_extension(windows_train_path, 'npy')\n",
    "train_files = train_files[:train_data_limit]\n",
    "\n",
    "train_dataset = m.create_tf_dataset_batched(\n",
    "    train_files, \n",
    "    batch_size=cluster_batch_size, \n",
    "    buffer_size=cluster_buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "    autoencoder_model, \n",
    "    train_dataset, \n",
    "    latent_features_path, \n",
    "    features_name='latent_features_train',\n",
    "    return_array=False,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train KMEANS using latent features saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and sort latent feature files\n",
    "latent_features_files, num_latent_files = dp.list_files_by_extension(latent_features_path, 'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latent features from disk into a tensor dataset pipeline\n",
    "latent_features_dataset = m.create_latent_features_tf_dataset(\n",
    "    latent_features_files,\n",
    "    batch_size=cluster_batch_size,\n",
    "    shuffle=True, \n",
    "    shuffle_buffer_size=cluster_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model, convergence_history = m.train_kmeans(\n",
    "    latent_features_dataset,                # tf.data.Dataset containing batches of latent feature vectors.\n",
    "    batch_size=cluster_batch_size,          # Size of each batch for the KMeans model (controls memory usage and stability).\n",
    "    num_clusters=num_clusters,              # Desired number of clusters (centroids) to form in the data.\n",
    "    n_init=n_init,                          # Number of times the algorithm will run with different centroid seeds.\n",
    "    max_iter=max_iter,                      # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "    reassignment_ratio=reassignment_ratio   # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    ")\n",
    "\n",
    "# Save cluster model\n",
    "m.save_cluster_model(cluster_model, cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Matrix format data to windows for making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.delete_data_folders(\n",
    "    job_data_path, \n",
    "    subdirectories=['windows/predict','windows-jpg/predict','jpg/predict'],\n",
    "    override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data in MTRX format\n",
    "mtrx_predict_file_list, _ = dp.list_files_by_extension(mtrx_predict_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_predict_file_list,\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, \n",
    "    window_pitch = predict_window_pitch,\n",
    "    save_windows = save_windows,\n",
    "    save_window_jpgs=save_window_jpgs,\n",
    "    save_jpg = save_jpg,\n",
    "    together = together,\n",
    "    collate = collate,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using the trained autoencoder and KMEANS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained autoencoder\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)\n",
    "\n",
    "# Load a previously saved cluster model from disk\n",
    "cluster_model = m.load_cluster_model(cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of image windows files to make predictions on\n",
    "predict_data_files_list, predict_data_files_num = dp.list_files_by_extension(windows_predict_path,'.npy',verbose=False)\n",
    "# Get the corresponding image coordimages list file\n",
    "image_windows_coordinates_file_list , _ = dp.list_files_by_extension(windows_predict_path,'.txt',verbose=False)\n",
    "image_windows_coordinates_file_list = [\n",
    "    name for name in image_windows_coordinates_file_list \n",
    "    if \"coordinates\" in name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the image windows and save the latent features to disk\n",
    "for prediction_file, coords_file in zip(predict_data_files_list,image_windows_coordinates_file_list):\n",
    "    # Load the windows for the image as a numpy file\n",
    "    image_windows = np.load(prediction_file)\n",
    "    # Load the image window coordinates\n",
    "    image_windows_coordinates = dp.load_coordinates_file(coords_file)\n",
    "    # Reconstruct the original image from the loaded image windows\n",
    "    reconstructed_img = dp.reconstruct_image(image_windows,image_windows_coordinates,window_size)\n",
    "    \n",
    "    # Make a tensorflow data pipeline of just the image windows for this image.\n",
    "    num_windows = image_windows.shape[0]\n",
    "    print('\\n---\\nProcessing file {}'.format(os.path.basename(prediction_file)))\n",
    "   \n",
    "    # Predictions windows\n",
    "    predict_dataset = m.create_tf_dataset_batched(\n",
    "        [prediction_file], \n",
    "        batch_size=num_windows, \n",
    "        buffer_size=num_windows, \n",
    "        window_size=window_size,\n",
    "        is_autoencoder=False, \n",
    "        shuffle=False)\n",
    "   \n",
    "    # make the latent features for each window using the autoencoder model \n",
    "    latent_predict_features, num_latent_predictions = m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "        autoencoder_model, \n",
    "        predict_dataset, \n",
    "        '',                 # we are not saving these predictions to disk so don't need a folder or name\n",
    "        features_name='',\n",
    "        return_array=True,\n",
    "        verbose=False)\n",
    "    \n",
    "    # make preductions \n",
    "    cluster_predictions = cluster_model.predict(latent_predict_features)\n",
    "    \n",
    "    # Build the reconstruction of the predicted cluster label data\n",
    "    cluster_img = dp.reconstruct_cluster_image(image_windows_coordinates,window_size, cluster_predictions)\n",
    "    \n",
    "    # Pad the cluster image to the original image size\n",
    "    cluster_img = ut.padded_cluster_img = ut.pad_cluster_image(reconstructed_img,cluster_img,window_size)\n",
    "    image_name = os.path.splitext(os.path.basename(prediction_file))[0]\n",
    "  \n",
    "    m.display_reconstructed_and_cluster_images(reconstructed_img,cluster_img,\n",
    "                                                show_overlay=True,\n",
    "                                                save_to_disk=True,\n",
    "                                                output_path=predictions_path,\n",
    "                                                image_name=image_name,\n",
    "                                                dpi=150)  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = cluster_img\n",
    "\n",
    "# # Function to display pixel values on click\n",
    "# def on_click(event):\n",
    "#     # Check if the click is on the image\n",
    "#     if event.inaxes:\n",
    "#         # Get the row and column indices\n",
    "#         col, row = int(event.xdata + 0.5), int(event.ydata + 0.5)\n",
    "#         # Get the pixel value\n",
    "#         pixel_value = data[row, col]\n",
    "#         print(f\"Clicked on ({row}, {col}) with value: {pixel_value}\")\n",
    "\n",
    "# # Plot the image\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))  # Adjust figsize (width, height) as desired\n",
    "# cax = ax.imshow(data, cmap='viridis', interpolation='nearest')\n",
    "# fig.colorbar(cax, ax=ax)\n",
    "# ax.set_title(\"Click on the image to get pixel value\")\n",
    "\n",
    "# # Connect the click event to the function\n",
    "# cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(int(np.max(cluster_img))):\n",
    "#     plt.imshow(cluster_img==i, cmap='viridis')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def summarize_programme_parameters_pandas(save_path=None):\n",
    "    # Create a dictionary for all parameters\n",
    "    parameters = {\n",
    "        \"Parameter\": [\n",
    "            \"Job Name\", \n",
    "            \"Flatten Method\", \"Pixel Density\", \"Pixel Ratio\", \"Data Scaling\", \"Window Size\",\n",
    "            \"Window Pitch\", \"Model Name\",\n",
    "            \"Batch Size\", \"Buffer Size\", \"Learning Rate\", \"Epochs\", \"Cluster Model Name\",\n",
    "            \"Cluster Batch Size\", \"Cluster Buffer Size\", \"Number of Clusters\",\n",
    "            \"Initialization Attempts\", \"Max Iterations\", \"Reassignment Ratio\",\n",
    "            \"Prediction Window Pitch\", \"Training Data Limit\", \"Testing Data Limit\",\n",
    "            \"Matrix Training Data Limit\", \"Matrix Testing Data Limit\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            job_name, \n",
    "            flatten_method, pixel_density, pixel_ratio, data_scaling, window_size,\n",
    "            window_pitch, model_name+'_'+model_train_time, batch_size, buffer_size,\n",
    "            learning_rate, epochs, cluster_model_name, cluster_batch_size, cluster_buffer_size,\n",
    "            num_clusters, n_init, max_iter, reassignment_ratio, predict_window_pitch,\n",
    "            train_data_limit, test_data_limit, mtrx_train_data_limit, mtrx_test_data_limit\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(parameters)\n",
    "\n",
    "    # Display in notebook\n",
    "    display(Markdown(\"## Parameters Summary - {}\".format(model_train_time)))\n",
    "    display(df)\n",
    "\n",
    "    # Save if path is given\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        csv_filename = os.path.join(save_path, f\"parameter_summary_{model_train_time}.csv\")\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Saved parameter summary to {csv_filename}\")\n",
    "\n",
    "\n",
    "# Call the function to display the summary\n",
    "summarize_programme_parameters_pandas(save_path=predictions_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
