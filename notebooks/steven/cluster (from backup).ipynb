{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # CNN autoencoder and Clustering from MTRX data\n",
    "\n",
    "Use this notebook to load Scienta Omicron Matrix format SPM data and create standardised images for machine learning training and analysis. The code can generate both JPG image data, useful for manually checking the data, and windowed numpy data that can be loaded into ML models. \n",
    "\n",
    "The notebook then creates an autoencoder for training on a large dataset, followed by KMEANS clustering. \n",
    "\n",
    "**Author**: Steven R. Schofield  \n",
    "**Created**: November, 2024 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning autoencoder + Kmeans for STM image data analysis\n",
    "## Steven R. Schofield (Universtiy College London Dec. 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path = /Users/steven/academic-iCloud/Python/modules\n",
      "data_path = /Users/steven/Python-data\n"
     ]
    }
   ],
   "source": [
    "# Define path where to find the module. This allows for a different path depending on where the code is running (my mac or the cluster)\n",
    "import os\n",
    "\n",
    "module_path_list = [\n",
    "    '/Users/steven/academic-iCloud/Python/modules',\n",
    "    '/hpc/srs/Python/modules'\n",
    "] \n",
    "\n",
    "data_path_list = [\n",
    "    '/Users/steven/Python-data',\n",
    "    '/hpc/srs/Python-data'\n",
    "]\n",
    "\n",
    "module_path = next((p for p in module_path_list if os.path.exists(p)), None)\n",
    "if not module_path:\n",
    "    exit(\"No valid module paths.\")\n",
    "else:\n",
    "    print('module_path = {}'.format(module_path))\n",
    "\n",
    "data_path = next((p for p in data_path_list if os.path.exists(p)), None)\n",
    "if not module_path:\n",
    "    exit(\"No valid data paths.\")\n",
    "else:\n",
    "    print('data_path = {}'.format(data_path))\n",
    "\n",
    "# adjust tensorflow output level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 0 default all messages, 1 warnings and errors, 2, errors, 3 fatal errors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version: 3.8.18 (default, Sep 11 2023, 08:17:16) \n",
      "[Clang 14.0.6 ]\n",
      "TensorFlow version: 2.13.0\n",
      "TensorFlow is built with CUDA: False\n",
      "TensorFlow is built with ROCm: False\n",
      "\n",
      "System: Darwin 24.1.0 (arm64)\n",
      "Platform: macOS-15.1.1-arm64-arm-64bit\n",
      "Processor: arm\n",
      "\n",
      "Number of GPUs available to TensorFlow: 1\n",
      "GPU Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "\n",
      ">>> Running with GPU available <<<  (macOS-15.1.1-arm64-arm-64bit)\n",
      "\n",
      "Current time 2025-01-03 18:04:19\n"
     ]
    }
   ],
   "source": [
    "# # Ensure modules are reloaded \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "import platform\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Add custom module path to list\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Import custom module\n",
    "import SRSML24.data_prep as dp\n",
    "import SRSML24.model as m\n",
    "import SRSML24.utils as ut\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.optimizers.legacy import Adam \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import platform \n",
    "\n",
    "m.print_system_info()\n",
    "\n",
    "start_time = dp.current_datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programme variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for windows creation\n",
    "job_name = 'MSc2024_Data'\n",
    "job_data_path = dp.create_new_data_path(data_path, job_name, include_date=False)\n",
    "mtrx_train_path = os.path.join(data_path, 'mtrx/train')\n",
    "mtrx_test_path = os.path.join(data_path, 'mtrx/test')\n",
    "mtrx_predict_path = os.path.join(data_path, 'mtrx/predict')\n",
    "flatten_method = 'poly_xy'\n",
    "pixel_density = 15.0        # Convert all images to a constant pixel density\n",
    "pixel_ratio = 0.7           # If an image has less than this % in the slow scan direction it is discarded\n",
    "data_scaling = 1.e9         # Scale the z-height of the data\n",
    "window_size = 16            # Window size for training/validation\n",
    "window_pitch = 8            # Window pitch for training/validation\n",
    "together = True             # Set this True to save image windows for a mtrx image as a single file rather than separate files.\n",
    "collate = False             # Set this True to remove all subfolder directories and save all data in root data path\n",
    "save_window_jpgs = False    # Save the windows as jpgs for inspection\n",
    "save_windows = True         # Save the windows as numpy files\n",
    "save_jpg = False            # Save the full image as a jpg\n",
    "verbose = False             # Set this True to print out more information\n",
    "\n",
    "# Parameters for training\n",
    "model_name = 'unet_' + job_name\n",
    "batch_size = 128\n",
    "buffer_size = 12800 # shuffling\n",
    "learning_rate = 1e-4\n",
    "epochs = 5\n",
    "\n",
    "# Parameters for clustering\n",
    "cluster_model_name = model_name + '_kmeans'\n",
    "cluster_batch_size = 5120 # This is the number of latent features in a batch for clustering. \n",
    "                          # Does not have to be the same as for training and probably should \n",
    "                          # be larger. \n",
    "cluster_buffer_size = cluster_batch_size * 5    # shuffling buffer\n",
    "num_clusters=20                                 # Desired number of clusters (centroids) to form in the data.\n",
    "n_init=50                                       # Number of times the algorithm will run with different centroid seeds.\n",
    "max_iter=1000                                   # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "reassignment_ratio=0.05                         # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    "\n",
    "# Parameters for PREDICTIONS\n",
    "predict_window_pitch = 4                        # Window pitch for prediction\n",
    "\n",
    "# DATA LIMITS FOR TESTING THE CODE\n",
    "mtrx_train_data_limit = 200 #None                    # Number of MTRX files to process (training)\n",
    "mtrx_test_data_limit = 20 #None                     # Number of MTRX files to process (validation)\n",
    "\n",
    "train_data_limit = None                         # Limit the data used in the autoencoder training\n",
    "test_data_limit = None                          # Limit the data used in the autoencoder training (validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Matrix format data to windows for autoencoder training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REMOVE ALL DATA FOLDERS EXCEPT MTRX \n",
    "# dp.delete_data_folders(job_data_path, subdirectories=[\"jpg\", \"windows\", \"windows-jpg\"], override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training data\n",
    "# mtrx_train_file_list, _ = dp.list_files_by_extension(mtrx_train_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "# dp.process_mtrx_files(\n",
    "#     mtrx_train_file_list[0:mtrx_train_data_limit],\n",
    "#     job_data_path, # save data path\n",
    "#     flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "#     data_scaling = data_scaling, window_size = window_size, window_pitch = window_pitch,\n",
    "#     save_windows = save_windows,\n",
    "#     save_window_jpgs=save_window_jpgs,\n",
    "#     save_jpg = save_jpg,\n",
    "#     together = together,\n",
    "#     collate = collate,\n",
    "#     verbose = verbose\n",
    "#     )\n",
    "\n",
    "# # Test data\n",
    "# mtrx_test_file_list, _ = dp.list_files_by_extension(mtrx_test_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "# dp.process_mtrx_files(\n",
    "#     mtrx_test_file_list[0:mtrx_test_data_limit],\n",
    "#     job_data_path, # save data path\n",
    "#     flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "#     data_scaling = data_scaling, window_size = window_size, window_pitch = window_pitch,\n",
    "#     save_windows = save_windows,\n",
    "#     save_window_jpgs=save_window_jpgs,\n",
    "#     save_jpg = save_jpg,\n",
    "#     together = together,\n",
    "#     collate = collate,\n",
    "#     verbose = verbose\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build tensorflow data pipeline for training and validation of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 files with extension 'npy' in directory:\n",
      "/Users/steven/Python-data/MSc2024_Data/windows/train\n",
      "Data pipeline created with 217 files, batch size: 128, window size: 16\n",
      "Sample batch shape: (128, 16, 16, 1)\n",
      "\n",
      "Found 2 files with extension 'npy' in directory:\n",
      "/Users/steven/Python-data/MSc2024_Data/windows/test\n",
      "Data pipeline created with 2 files, batch size: 128, window size: 16\n",
      "Sample batch shape: (128, 16, 16, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training data - tensorflow data pipeline for autoencoder\n",
    "windows_train_path = os.path.join(job_data_path, 'windows/train')\n",
    "train_files, num_train = dp.list_files_by_extension(windows_train_path, 'npy')\n",
    "train_files = train_files[:train_data_limit]\n",
    "\n",
    "# Create dataset with prefetching\n",
    "train_dataset = m.create_tf_dataset_batched(\n",
    "    train_files, \n",
    "    batch_size=batch_size, \n",
    "    buffer_size=buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)\n",
    "\n",
    "# Validation data - tensorflow data pipeline for autoencoder\n",
    "windows_test_path = os.path.join(job_data_path, 'windows/test')\n",
    "test_files, num_test = dp.list_files_by_extension(windows_test_path, 'npy')\n",
    "test_files = test_files[:test_data_limit]\n",
    "\n",
    "# Create dataset with prefetching\n",
    "test_dataset = m.create_tf_dataset_batched(\n",
    "    test_files, \n",
    "    batch_size=batch_size, \n",
    "    buffer_size=buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build and compile the UNET model\n",
    "# autoencoder_model = m.build_autoencoder(window_size=window_size,model_name=model_name)\n",
    "# autoencoder_model.summary()\n",
    "\n",
    "# # Check if running on Apple Silicon\n",
    "# is_mac_silicon = platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n",
    "\n",
    "# if is_mac_silicon:\n",
    "#     print(\"Detected Mac with Apple Silicon. Compiling the model with the legacy RMSprop optimizer for compatibility with TensorFlow-metal.\")\n",
    "#     autoencoder_model.compile(\n",
    "#         optimizer=tf.keras.optimizers.legacy.RMSprop(learning_rate=learning_rate),\n",
    "#         loss='mean_squared_error',\n",
    "#         metrics=['mse', 'mae']\n",
    "#     )\n",
    "# else:\n",
    "#     print(\"Compiling the model with the RMSprop optimizer.\")\n",
    "#     autoencoder_model.compile(\n",
    "#         optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "#         loss='mean_squared_error',\n",
    "#         metrics=['mse', 'mae']\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model using the tf.data datasets\n",
    "# history = autoencoder_model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=test_dataset,\n",
    "#     epochs=epochs,\n",
    "#     shuffle=True,\n",
    "#     verbose=1\n",
    "# )\n",
    "# model_train_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# # Save the model as soon as training completes\n",
    "# model_path = os.path.join(job_data_path,'model')\n",
    "# m.save_model(autoencoder_model, model_path, model_name=model_name, model_train_time=model_train_time)\n",
    "\n",
    "# end_time = dp.current_datetime()\n",
    "# dp.elapsed_time(start_time,end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot training history\n",
    "# m.plot_training_history(history, \n",
    "#                         loss_name='loss', \n",
    "#                         val_loss_name='val_loss', \n",
    "#                         metric_names=['mse', 'mae'], \n",
    "#                         save_to_disk=True,\n",
    "#                         model_name=model_name, \n",
    "#                         model_train_time=model_train_time,\n",
    "#                         val_metric_names=['val_mse', 'val_mae'],\n",
    "#                         output_path=model_path,\n",
    "#                         dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Latent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.delete_data_folders(\n",
    "#     job_data_path, \n",
    "#     subdirectories='latent_features',\n",
    "#     override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/steven/Python-data/MSc2024_Data/model/unet_MSc2024_Data.keras\n"
     ]
    }
   ],
   "source": [
    "# Load the trained autoencoder model\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 files with extension 'npy' in directory:\n",
      "/Users/steven/Python-data/MSc2024_Data/windows/train\n",
      "Data pipeline created with 217 files, batch size: 5120, window size: 16\n",
      "Sample batch shape: (5120, 16, 16, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training data - tensorflow data pipeline \n",
    "windows_train_path = os.path.join(job_data_path, 'windows/train')\n",
    "train_files, num_train = dp.list_files_by_extension(windows_train_path, 'npy')\n",
    "train_files = train_files[:train_data_limit]\n",
    "\n",
    "train_dataset = m.create_tf_dataset_batched(\n",
    "    train_files, \n",
    "    batch_size=cluster_batch_size, \n",
    "    buffer_size=cluster_buffer_size, \n",
    "    window_size=window_size,\n",
    "    is_autoencoder=True, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to save latent features to disk\n",
    "# latent_features_path = os.path.join(job_data_path, 'latent_features')\n",
    "\n",
    "# m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "#     autoencoder_model, \n",
    "#     train_dataset, \n",
    "#     latent_features_path, \n",
    "#     features_name='latent_features_train',\n",
    "#     return_array=False,\n",
    "#     verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train KMEANS using latent features saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 159 files with extension 'npy' in directory:\n",
      "/Users/steven/Python-data/MSc2024_Data/latent_features\n"
     ]
    }
   ],
   "source": [
    "# List and sort latent feature files\n",
    "latent_features_path = os.path.join(job_data_path, 'latent_features')\n",
    "latent_features_files, num_latent_files = dp.list_files_by_extension(latent_features_path, 'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pipeline created with 159 files, batch size: 5120\n",
      "Shuffling enabled with buffer size: 25600\n",
      "Batch shape: (5120, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Load the latent features from disk into a tensor dataset pipeline\n",
    "latent_features_dataset = m.create_latent_features_tf_dataset(\n",
    "    latent_features_files,\n",
    "    batch_size=cluster_batch_size,\n",
    "    shuffle=True, \n",
    "    shuffle_buffer_size=cluster_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: RuntimeWarning: Explicit initial center position passed: performing only one init in MiniBatchKMeans instead of n_init=50.\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed. Inertia: 170.38534545898438\n",
      "Batch 2 processed. Inertia: 167.76954650878906\n",
      "Batch 3 processed. Inertia: 172.38441467285156\n",
      "Batch 4 processed. Inertia: 166.822509765625\n",
      "Batch 5 processed. Inertia: 174.10671997070312\n",
      "Batch 6 processed. Inertia: 167.84454345703125\n",
      "Batch 7 processed. Inertia: 168.73667907714844\n",
      "Batch 8 processed. Inertia: 172.84779357910156\n",
      "Batch 9 processed. Inertia: 173.752197265625\n",
      "Batch 10 processed. Inertia: 170.63973999023438\n",
      "Batch 11 processed. Inertia: 170.47056579589844\n",
      "Batch 12 processed. Inertia: 169.163818359375\n",
      "Batch 13 processed. Inertia: 170.18507385253906\n",
      "Batch 14 processed. Inertia: 174.143310546875\n",
      "Batch 15 processed. Inertia: 171.4431610107422\n",
      "Batch 16 processed. Inertia: 170.62582397460938\n",
      "Batch 17 processed. Inertia: 167.7606964111328\n",
      "Batch 18 processed. Inertia: 165.46514892578125\n",
      "Batch 19 processed. Inertia: 170.24818420410156\n",
      "Batch 20 processed. Inertia: 173.92453002929688\n",
      "Batch 21 processed. Inertia: 167.010498046875\n",
      "Batch 22 processed. Inertia: 168.24362182617188\n",
      "Batch 23 processed. Inertia: 168.05349731445312\n",
      "Batch 24 processed. Inertia: 170.4279327392578\n",
      "Batch 25 processed. Inertia: 175.7511444091797\n",
      "Batch 26 processed. Inertia: 169.16543579101562\n",
      "Batch 27 processed. Inertia: 168.10809326171875\n",
      "Batch 28 processed. Inertia: 167.86231994628906\n",
      "Batch 29 processed. Inertia: 167.8391571044922\n",
      "Batch 30 processed. Inertia: 170.18997192382812\n",
      "Batch 31 processed. Inertia: 166.95114135742188\n",
      "Batch 32 processed. Inertia: 167.5258331298828\n",
      "Batch 33 processed. Inertia: 172.4741973876953\n",
      "Batch 34 processed. Inertia: 168.10595703125\n",
      "Batch 35 processed. Inertia: 167.22035217285156\n",
      "Batch 36 processed. Inertia: 171.27020263671875\n",
      "Batch 37 processed. Inertia: 171.66293334960938\n",
      "Batch 38 processed. Inertia: 169.33087158203125\n",
      "Batch 39 processed. Inertia: 167.87469482421875\n",
      "Batch 40 processed. Inertia: 167.09432983398438\n",
      "Batch 41 processed. Inertia: 167.30441284179688\n",
      "Batch 42 processed. Inertia: 169.3025360107422\n",
      "Batch 43 processed. Inertia: 166.23748779296875\n",
      "Batch 44 processed. Inertia: 172.3701629638672\n",
      "Batch 45 processed. Inertia: 172.71249389648438\n",
      "Batch 46 processed. Inertia: 174.71722412109375\n",
      "Batch 47 processed. Inertia: 171.40476989746094\n",
      "Batch 48 processed. Inertia: 166.48768615722656\n",
      "Batch 49 processed. Inertia: 173.83633422851562\n",
      "Batch 50 processed. Inertia: 168.16253662109375\n",
      "Batch 51 processed. Inertia: 169.07603454589844\n",
      "Batch 52 processed. Inertia: 164.12448120117188\n",
      "Batch 53 processed. Inertia: 168.69012451171875\n",
      "Batch 54 processed. Inertia: 173.350830078125\n",
      "Batch 55 processed. Inertia: 170.1717071533203\n",
      "Batch 56 processed. Inertia: 179.6522674560547\n",
      "Batch 57 processed. Inertia: 168.76473999023438\n",
      "Batch 58 processed. Inertia: 166.7307891845703\n",
      "Batch 59 processed. Inertia: 171.94580078125\n",
      "Batch 60 processed. Inertia: 170.81216430664062\n",
      "Batch 61 processed. Inertia: 169.90383911132812\n",
      "Batch 62 processed. Inertia: 172.51429748535156\n",
      "Batch 63 processed. Inertia: 166.4141845703125\n",
      "Batch 64 processed. Inertia: 167.58413696289062\n",
      "Batch 65 processed. Inertia: 171.50241088867188\n",
      "Batch 66 processed. Inertia: 166.614501953125\n",
      "Batch 67 processed. Inertia: 172.7339324951172\n",
      "Batch 68 processed. Inertia: 168.09033203125\n",
      "Batch 69 processed. Inertia: 172.78794860839844\n",
      "Batch 70 processed. Inertia: 174.93264770507812\n",
      "Batch 71 processed. Inertia: 167.97137451171875\n",
      "Batch 72 processed. Inertia: 165.51058959960938\n",
      "Batch 73 processed. Inertia: 166.613525390625\n",
      "Batch 74 processed. Inertia: 167.40008544921875\n",
      "Batch 75 processed. Inertia: 175.2960205078125\n",
      "Batch 76 processed. Inertia: 166.7442169189453\n",
      "Batch 77 processed. Inertia: 169.9754638671875\n",
      "Batch 78 processed. Inertia: 174.21202087402344\n",
      "Batch 79 processed. Inertia: 166.63587951660156\n",
      "Batch 80 processed. Inertia: 171.21630859375\n",
      "Batch 81 processed. Inertia: 165.12904357910156\n",
      "Batch 82 processed. Inertia: 168.11170959472656\n",
      "Batch 83 processed. Inertia: 167.65916442871094\n",
      "Batch 84 processed. Inertia: 170.4931640625\n",
      "Batch 85 processed. Inertia: 168.16018676757812\n",
      "Batch 86 processed. Inertia: 167.71664428710938\n",
      "Batch 87 processed. Inertia: 168.7813720703125\n",
      "Batch 88 processed. Inertia: 170.93760681152344\n",
      "Batch 89 processed. Inertia: 166.7632598876953\n",
      "Batch 90 processed. Inertia: 170.59762573242188\n",
      "Batch 91 processed. Inertia: 168.12989807128906\n",
      "Batch 92 processed. Inertia: 167.51600646972656\n",
      "Batch 93 processed. Inertia: 165.47622680664062\n",
      "Batch 94 processed. Inertia: 167.0078125\n",
      "Batch 95 processed. Inertia: 172.4450225830078\n",
      "Batch 96 processed. Inertia: 167.60411071777344\n",
      "Batch 97 processed. Inertia: 170.88046264648438\n",
      "Batch 98 processed. Inertia: 174.9877166748047\n",
      "Batch 99 processed. Inertia: 168.54376220703125\n",
      "Batch 100 processed. Inertia: 170.14642333984375\n",
      "Batch 101 processed. Inertia: 166.29629516601562\n",
      "Batch 102 processed. Inertia: 167.1363983154297\n",
      "Batch 103 processed. Inertia: 165.34347534179688\n",
      "Batch 104 processed. Inertia: 169.4718475341797\n",
      "Batch 105 processed. Inertia: 166.53689575195312\n",
      "Batch 106 processed. Inertia: 169.24424743652344\n",
      "Batch 107 processed. Inertia: 166.75372314453125\n",
      "Batch 108 processed. Inertia: 175.70993041992188\n",
      "Batch 109 processed. Inertia: 166.57830810546875\n",
      "Batch 110 processed. Inertia: 166.09133911132812\n",
      "Batch 111 processed. Inertia: 167.71524047851562\n",
      "Batch 112 processed. Inertia: 168.6495819091797\n",
      "Batch 113 processed. Inertia: 171.3134765625\n",
      "Batch 114 processed. Inertia: 166.47508239746094\n",
      "Batch 115 processed. Inertia: 170.9586181640625\n",
      "Batch 116 processed. Inertia: 165.47601318359375\n",
      "Batch 117 processed. Inertia: 163.70616149902344\n",
      "Batch 118 processed. Inertia: 169.1057891845703\n",
      "Batch 119 processed. Inertia: 172.26541137695312\n",
      "Batch 120 processed. Inertia: 167.05392456054688\n",
      "Batch 121 processed. Inertia: 164.45278930664062\n",
      "Batch 122 processed. Inertia: 168.40963745117188\n",
      "Batch 123 processed. Inertia: 169.6954345703125\n",
      "Batch 124 processed. Inertia: 166.5502166748047\n",
      "Batch 125 processed. Inertia: 168.48268127441406\n",
      "Batch 126 processed. Inertia: 166.50033569335938\n",
      "Batch 127 processed. Inertia: 168.81973266601562\n",
      "Batch 128 processed. Inertia: 167.44688415527344\n",
      "Batch 129 processed. Inertia: 168.81069946289062\n",
      "Batch 130 processed. Inertia: 167.226806640625\n",
      "Batch 131 processed. Inertia: 165.9180908203125\n",
      "Batch 132 processed. Inertia: 164.99111938476562\n",
      "Batch 133 processed. Inertia: 172.68812561035156\n",
      "Batch 134 processed. Inertia: 165.29087829589844\n",
      "Batch 135 processed. Inertia: 173.5794677734375\n",
      "Batch 136 processed. Inertia: 171.0990753173828\n",
      "Batch 137 processed. Inertia: 167.38504028320312\n",
      "Batch 138 processed. Inertia: 169.04522705078125\n",
      "Batch 139 processed. Inertia: 167.89451599121094\n",
      "Batch 140 processed. Inertia: 172.61599731445312\n",
      "Batch 141 processed. Inertia: 166.59255981445312\n",
      "Batch 142 processed. Inertia: 170.29080200195312\n",
      "Batch 143 processed. Inertia: 168.8855438232422\n",
      "Batch 144 processed. Inertia: 172.23345947265625\n",
      "Batch 145 processed. Inertia: 171.39541625976562\n",
      "Batch 146 processed. Inertia: 171.00437927246094\n",
      "Batch 147 processed. Inertia: 171.91860961914062\n",
      "Batch 148 processed. Inertia: 170.23306274414062\n",
      "Batch 149 processed. Inertia: 167.72109985351562\n",
      "Batch 150 processed. Inertia: 167.00320434570312\n",
      "Batch 151 processed. Inertia: 168.2513885498047\n",
      "Batch 152 processed. Inertia: 167.1136932373047\n",
      "Batch 153 processed. Inertia: 168.77023315429688\n",
      "Batch 154 processed. Inertia: 166.88467407226562\n",
      "Batch 155 processed. Inertia: 172.76329040527344\n",
      "Batch 156 processed. Inertia: 164.94602966308594\n",
      "Batch 157 processed. Inertia: 168.52700805664062\n",
      "Batch 158 processed. Inertia: 168.06698608398438\n",
      "Batch 159 processed. Inertia: 7.550449371337891\n",
      "Final inertia after training: 7.550449371337891\n",
      "Cluster model saved at: /Users/steven/Python-data/MSc2024_Data/cluster_model/unet_MSc2024_Data_kmeans.pkl\n"
     ]
    }
   ],
   "source": [
    "cluster_model, convergence_history = m.train_kmeans(\n",
    "    latent_features_dataset,                # tf.data.Dataset containing batches of latent feature vectors.\n",
    "    batch_size=cluster_batch_size,          # Size of each batch for the KMeans model (controls memory usage and stability).\n",
    "    num_clusters=num_clusters,              # Desired number of clusters (centroids) to form in the data.\n",
    "    n_init=n_init,                          # Number of times the algorithm will run with different centroid seeds.\n",
    "    max_iter=max_iter,                      # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "    reassignment_ratio=reassignment_ratio   # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    ")\n",
    "\n",
    "# Save cluster model\n",
    "cluster_model_path = os.path.join(job_data_path,'cluster_model')\n",
    "m.save_cluster_model(cluster_model, cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Matrix format data to windows for making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.delete_data_folders(\n",
    "#     job_data_path, \n",
    "#     subdirectories=['windows/predict','windows-jpg/predict','jpg/predict'],\n",
    "#     override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction data in MTRX format\n",
    "# mtrx_predict_file_list, _ = dp.list_files_by_extension(mtrx_predict_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "# dp.process_mtrx_files(\n",
    "#     mtrx_predict_file_list,\n",
    "#     job_data_path, # save data path\n",
    "#     flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "#     data_scaling = data_scaling, window_size = window_size, \n",
    "#     window_pitch = predict_window_pitch,\n",
    "#     save_windows = save_windows,\n",
    "#     save_window_jpgs=save_window_jpgs,\n",
    "#     save_jpg = save_jpg,\n",
    "#     together = together,\n",
    "#     collate = collate,\n",
    "#     verbose = verbose\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to summarize programme parameters using pandas\n",
    "# import pandas as pd\n",
    "# def summarize_programme_parameters_pandas():\n",
    "#     # Create a dictionary for all parameters\n",
    "#     parameters = {\n",
    "#         \"Parameter\": [\n",
    "#             \"Job Name\", \n",
    "#             \"Flatten Method\", \"Pixel Density\", \"Pixel Ratio\", \"Data Scaling\", \"Window Size\",\n",
    "#             \"Window Pitch\", \"Save as Single File\", \"Collate in Root Directory\", \"Model Name\",\n",
    "#             \"Batch Size\", \"Buffer Size\", \"Learning Rate\", \"Epochs\", \"Cluster Model Name\",\n",
    "#             \"Cluster Batch Size\", \"Cluster Buffer Size\", \"Number of Clusters\",\n",
    "#             \"Initialization Attempts\", \"Max Iterations\", \"Reassignment Ratio\",\n",
    "#             \"Prediction Window Pitch\", \"Training Data Limit\", \"Testing Data Limit\",\n",
    "#             \"Matrix Training Data Limit\", \"Matrix Testing Data Limit\"\n",
    "#         ],\n",
    "#         \"Value\": [\n",
    "#             job_name, \n",
    "#             flatten_method, pixel_density, pixel_ratio, data_scaling, window_size,\n",
    "#             window_pitch, together, collate, model_name+'_'+model_train_time, batch_size, buffer_size,\n",
    "#             learning_rate, epochs, cluster_model_name, cluster_batch_size, cluster_buffer_size,\n",
    "#             num_clusters, n_init, max_iter, reassignment_ratio, predict_window_pitch,\n",
    "#             train_data_limit, test_data_limit, mtrx_train_data_limit, mtrx_test_data_limit\n",
    "#         ]\n",
    "#     }\n",
    "\n",
    "#     # Create a DataFrame from the dictionary\n",
    "#     df = pd.DataFrame(parameters)\n",
    "\n",
    "#     # Add a title above the DataFrame\n",
    "#     from IPython.display import display, Markdown\n",
    "#     display(Markdown(\"## Parameters Summary - {}\".format(model_train_time)))\n",
    "#     display(df)\n",
    "\n",
    "# # Call the function to display the summary\n",
    "# summarize_programme_parameters_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using the trained autoencoder and KMEANS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/steven/Python-data/MSc2024_Data/model/unet_MSc2024_Data.keras\n",
      "Cluster model loaded from: /Users/steven/Python-data/MSc2024_Data/cluster_model/unet_MSc2024_Data_kmeans.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the trained autoencoder\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)\n",
    "\n",
    "# Load a previously saved cluster model from disk\n",
    "cluster_model_path = os.path.join(job_data_path,'cluster_model')\n",
    "cluster_model = m.load_cluster_model(cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 files with extension '.npy' in directory:\n",
      "/Users/steven/Python-data/MSc2024_Data/windows/predict\n",
      "Found 64 files with extension '.txt' in directory:\n",
      "/Users/steven/Python-data/MSc2024_Data/windows/predict\n",
      "Using matplotlib backend: MacOSX\n",
      "\n",
      "---\n",
      "Processing file default_2011Feb11-105510_STM-STM_Spectroscopy--110_16_BD_all_windows.npy\n",
      "Not shuffling\n",
      "Data pipeline created with 1 files, batch size: 49284, window size: 16\n",
      "Sample batch shape: (49284, 16, 16, 1)\n",
      ".Combined latent features shape: (49284, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Folder where image prediction windows are stored. \n",
    "windows_predict_path = os.path.join(job_data_path, 'windows/predict')\n",
    "# Get the list of image windows files to make predictions on\n",
    "predict_data_files_list, predict_data_files_num = dp.list_files_by_extension(windows_predict_path,'.npy',verbose=False)\n",
    "# Get the corresponding image coordimages list file\n",
    "image_windows_coordinates_file_list , _ = dp.list_files_by_extension(windows_predict_path,'.txt',verbose=False)\n",
    "image_windows_coordinates_file_list = [\n",
    "    name for name in image_windows_coordinates_file_list \n",
    "    if \"coordinates\" in name\n",
    "]\n",
    "\n",
    "# Folder to save latent_feature_predictions\n",
    "predict_latent_features_path = os.path.join(job_data_path, 'latent_features_predictions')\n",
    "\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "\n",
    "# Make predictions on the image windows and save the latent features to disk\n",
    "for prediction_file, coords_file in zip(predict_data_files_list,image_windows_coordinates_file_list):\n",
    "    # Load the windows for the image as a numpy file\n",
    "    image_windows = np.load(prediction_file)\n",
    "    # Load the image window coordinates\n",
    "    image_windows_coordinates = dp.load_coordinates_file(coords_file)\n",
    "    # Reconstruct the original image from the loaded image windows\n",
    "    reconstructed_img = dp.reconstruct_image(image_windows,image_windows_coordinates,window_size)\n",
    "    \n",
    "    # Make a tensorflow data pipeline of just the image windows for this image.\n",
    "    num_windows = image_windows.shape[0]\n",
    "    print('\\n---\\nProcessing file {}'.format(os.path.basename(prediction_file)))\n",
    "    predict_dataset = m.create_tf_dataset_batched(\n",
    "        [prediction_file], \n",
    "        batch_size=num_windows, \n",
    "        buffer_size=num_windows, \n",
    "        window_size=window_size,\n",
    "        is_autoencoder=False, \n",
    "        shuffle=False)\n",
    "    # make the latent features for each window using the autoencoder model \n",
    "    latent_predict_features, num_latent_predictions = m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "        autoencoder_model, \n",
    "        predict_dataset, \n",
    "        '',                 # we are not saving these predictions to disk so don't need a folder or name\n",
    "        features_name='',\n",
    "        return_array=True,\n",
    "        verbose=False)\n",
    "    # make preductions \n",
    "    cluster_predictions = cluster_model.predict(latent_predict_features)\n",
    "    # Build the reconstruction of the predicted cluster label data\n",
    "    cluster_img = dp.reconstruct_cluster_image(image_windows_coordinates,window_size, cluster_predictions)\n",
    "    # Pad the cluster image to the original image size\n",
    "    cluster_img = ut.padded_cluster_img = ut.pad_cluster_image(reconstructed_img,cluster_img,window_size)\n",
    "    image_name = os.path.splitext(os.path.basename(prediction_file))[0]\n",
    "    # Path to save latent features to disk\n",
    "    predictions_path = os.path.join(job_data_path, 'predictions')\n",
    "    m.display_reconstructed_and_cluster_images(reconstructed_img,cluster_img,show_overlay=True,\n",
    "                                                save_to_disk=False,\n",
    "                                                #predictions_time_stamp=model_train_time,\n",
    "                                                output_path=job_data_path,\n",
    "                                                image_name=image_name,\n",
    "                                                dpi=150)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 17:59:59.662 python[90058:5249419] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-03 17:59:59.662 python[90058:5249419] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked on (444, 618) with value: 5.0\n",
      "Clicked on (513, 439) with value: 5.0\n",
      "Clicked on (499, 347) with value: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 18:00:10.641 python[90058:5249419] Warning: Window move completed without beginning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked on (428, 70) with value: 19.0\n",
      "Clicked on (776, 143) with value: 19.0\n",
      "Clicked on (496, 224) with value: 10.0\n",
      "Clicked on (379, 266) with value: 19.0\n",
      "Clicked on (168, 203) with value: 18.0\n",
      "Clicked on (151, 243) with value: 19.0\n",
      "Clicked on (157, 199) with value: 11.0\n"
     ]
    }
   ],
   "source": [
    "# data = cluster_img\n",
    "\n",
    "# # Function to display pixel values on click\n",
    "# def on_click(event):\n",
    "#     # Check if the click is on the image\n",
    "#     if event.inaxes:\n",
    "#         # Get the row and column indices\n",
    "#         col, row = int(event.xdata + 0.5), int(event.ydata + 0.5)\n",
    "#         # Get the pixel value\n",
    "#         pixel_value = data[row, col]\n",
    "#         print(f\"Clicked on ({row}, {col}) with value: {pixel_value}\")\n",
    "\n",
    "# # Plot the image\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))  # Adjust figsize (width, height) as desired\n",
    "# cax = ax.imshow(data, cmap='viridis', interpolation='nearest')\n",
    "# fig.colorbar(cax, ax=ax)\n",
    "# ax.set_title(\"Click on the image to get pixel value\")\n",
    "\n",
    "# # Connect the click event to the function\n",
    "# cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(np.max(cluster_img))):\n",
    "    plt.imshow(cluster_img==i, cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
