{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41ec92a",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "\n",
    "Working with windows from the entire image. The goal of this step is to segment the image and find the features of the image i.e. vacancies, adsorbed molecules. This is done by extracting the latent vectors from the bottleneck of an autoencoder for each window, clustering the latent vectors and reconstructing a cluster map with pixelwise clustering.\n",
    "\n",
    "Based on this pixelwise clustering, a feature detector finds the features of the clustered image, stores their (y,x) position in the image. The convention for coordinates is (y,x) because image sizes are usually given in (height, width).\n",
    "\n",
    "Then, we cut out windows of size (32,32) pixels around the position of the feature. These so called feature windows or `step2_windows` are then used in step 2.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Only working with feature windows extracted in step 1. The goal of this step is to cluster the feature windows i.e. classify the features into different classes using an unsupervised algorithm. This is done by retraining the autoencoder on the feature windows dataset to make it more tailored to extract features. The latent vectors are then clustered using a spectral clustering model. The result is an array of numbers, each number being a label.\n",
    "\n",
    "Then we circle the features on the original image, each circle having a different colour, depending on the label of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where to find the module. This allows for a different path depending on where the code is running (my mac or the cluster)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Define candidate paths\n",
    "module_path_list = [\n",
    "    '/Users/steven/academic-iCloud/Python/modules',\n",
    "    '/hpc/aklicka/Python/modules'\n",
    "]\n",
    "\n",
    "data_path_list = [\n",
    "    '/Users/steven/Python-data',\n",
    "    '/hpc/aklicka/Python-data/training-set-1'\n",
    "]\n",
    "\n",
    "# Resolve actual paths\n",
    "module_path = next((p for p in module_path_list if os.path.exists(p)), None)\n",
    "data_path = next((p for p in data_path_list if os.path.exists(p)), None)\n",
    "\n",
    "# Check and report missing paths\n",
    "if module_path is None:\n",
    "    print(\"Error: Could not locate a valid module path.\")\n",
    "if data_path is None:\n",
    "    print(\"Error: Could not locate a valid data path.\")\n",
    "\n",
    "if module_path is None or data_path is None:\n",
    "    sys.exit(1)\n",
    "\n",
    "# Print resolved paths\n",
    "print(f\"module_path = {module_path}\")\n",
    "print(f\"data_path = {data_path}\")\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure modules are reloaded \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard modules\n",
    "import numpy as np\n",
    "\n",
    "import platform\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Add custom module path to list\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Import custom module\n",
    "import SRSML24.data_prep as dp\n",
    "import SRSML24.model as m\n",
    "import SRSML24.utils as ut\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.optimizers.legacy import Adam \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import skimage as ski\n",
    "import skimage.morphology as morphology\n",
    "import skimage\n",
    "from skimage import morphology, measure\n",
    "\n",
    "#import platform \n",
    "\n",
    "m.print_system_info()\n",
    "\n",
    "start_time = dp.current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for windows creation\n",
    "# General\n",
    "job_name = 'June_25_BIG_model'\n",
    "verbose = False             # Set this True to print out more information\n",
    "\n",
    "# MTRX preprocessing\n",
    "flatten_method = 'poly_xy'\n",
    "pixel_density = 15.0        #Â Convert all images to a constant pixel density\n",
    "pixel_ratio = 0.7           # If an image has less than this % in the slow scan direction it is discarded\n",
    "data_scaling = 1.e9         # Scale the z-height of the data\n",
    "\n",
    "# Windowing\n",
    "window_size = 32            # Window size for training/validation\n",
    "window_pitch = 8            # Window pitch for training/validation\n",
    "\n",
    "# Data saving options\n",
    "save_windows = True         # Save the windows as numpy files\n",
    "together = True             # Set this True to save image windows for a mtrx image as a single file rather than separate files.\n",
    "save_jpg = False            # Save the full image as a jpg\n",
    "collate = False             # Set this True to remove all subfolder directories and save all data in root data path\n",
    "save_window_jpgs = False    # Save the windows as jpgs for inspection\n",
    "\n",
    "# Parameters for training\n",
    "model_name = 'unet_' + job_name\n",
    "batch_size = 128\n",
    "buffer_size = 12800 # shuffling\n",
    "learning_rate = 1e-4\n",
    "epochs = 5\n",
    "\n",
    "# Parameters for clustering\n",
    "cluster_model_name = model_name + '_kmeans'\n",
    "cluster_batch_size = 5120 # This is the number of latent features in a batch for clustering. \n",
    "                          # Does not have to be the same as for training and probably should \n",
    "                          # be larger. \n",
    "cluster_buffer_size = cluster_batch_size * 5    # shuffling buffer\n",
    "num_clusters=20                                 # Desired number of clusters (centroids) to form in the data.\n",
    "max_iter=1000                                   # Maximum iterations allowed for each mini-batch to refine centroids.\n",
    "reassignment_ratio=0.05                         # Fraction of clusters reassigned per step; lower values stabilize updates.\n",
    "\n",
    "# Parameters for PREDICTIONS\n",
    "predict_window_pitch = 2                        # Window pitch for prediction\n",
    "predictions_batch_size = 2**15                  # Batch size for predictions\n",
    "\n",
    "\n",
    "# DATA LIMITS FOR TESTING THE CODE\n",
    "mtrx_train_data_limit = None                    # Number of MTRX files to process (training)\n",
    "mtrx_test_data_limit = None                     # Number of MTRX files to process (validation)\n",
    "\n",
    "train_data_limit = 200                         # Limit the data used in the autoencoder training\n",
    "test_data_limit = 50                          # Limit the data used in the autoencoder training (validation)\n",
    "\n",
    "# Step 2\n",
    "cluster_model_spectral_name = model_name + \"_spectral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c88342e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_data_path = dp.create_new_data_path(data_path, job_name, include_date=False)\n",
    "\n",
    "mtrx_train_path = os.path.join(data_path, 'mtrx/train')\n",
    "mtrx_test_path = os.path.join(data_path, 'mtrx/test')\n",
    "mtrx_predict_path = os.path.join(data_path, 'mtrx/predict')\n",
    "\n",
    "# Step 1 paths\n",
    "model_path = os.path.join(job_data_path,'model')\n",
    "cluster_model_path = os.path.join(job_data_path,'cluster_model')\n",
    "\n",
    "latent_features_path = os.path.join(job_data_path, 'latent_features')\n",
    "predict_latent_features_path = os.path.join(job_data_path, 'latent_features_predictions')\n",
    "\n",
    "windows_train_path = os.path.join(job_data_path, 'windows/train')\n",
    "windows_test_path = os.path.join(job_data_path, 'windows/test')\n",
    "windows_predict_path = os.path.join(job_data_path, 'windows/predict')\n",
    "\n",
    "predictions_path = os.path.join(job_data_path, f'predictions')\n",
    "\n",
    "# Step 2 paths\n",
    "step2_model_path = os.path.join(job_data_path,'step2/model')\n",
    "step2_cluster_model_path = os.path.join(job_data_path,'step2/cluster_model')\n",
    "\n",
    "step2_latent_features_train_path = os.path.join(job_data_path, 'step2/latent_features/train')\n",
    "step2_latent_features_test_path = os.path.join(job_data_path, 'step2/latent_features/test')\n",
    "step2_latent_features_predict_path = os.path.join(job_data_path, 'step2/latent_features/predict')\n",
    "\n",
    "\n",
    "step2_predict_latent_features_path = os.path.join(job_data_path, 'step2/latent_features_predictions')\n",
    "\n",
    "\n",
    "step2_windows_train_path = os.path.join(job_data_path, 'step2/windows/train')\n",
    "step2_windows_test_path = os.path.join(job_data_path, 'step2/windows/test')\n",
    "step2_windows_predict_path = os.path.join(job_data_path, 'step2/windows/predict')\n",
    "\n",
    "step2_predictions_path = os.path.join(job_data_path, f'step2/predictions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83532948",
   "metadata": {},
   "source": [
    "### Process Matrix format data to windows for making predictions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407536c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.delete_data_folders(\n",
    "    job_data_path, \n",
    "    subdirectories=['windows/predict','windows-jpg/predict','jpg/predict'],\n",
    "    override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f65f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data in MTRX format\n",
    "mtrx_predict_file_list, _ = dp.list_files_by_extension(mtrx_predict_path,'Z_mtrx',verbose=False)\n",
    "\n",
    "dp.process_mtrx_files(\n",
    "    mtrx_predict_file_list,\n",
    "    job_data_path, # save data path\n",
    "    flatten_method = flatten_method, pixel_density = pixel_density, pixel_ratio = pixel_ratio,\n",
    "    data_scaling = data_scaling, window_size = window_size, \n",
    "    window_pitch = predict_window_pitch,\n",
    "    save_windows = save_windows,\n",
    "    save_window_jpgs=save_window_jpgs,\n",
    "    save_jpg = save_jpg,\n",
    "    together = together,\n",
    "    collate = collate,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4dd09",
   "metadata": {},
   "source": [
    "### Step 1: Making cluster image. Make predictions using the trained autoencoder and KMEANS models. Extract feature windows\n",
    "\n",
    "In step 1, all windows are used. Latent vectors relate to windows extracted from the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4622cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /hpc/aklicka/Python-data/training-set-1/June_25_BIG_model/model/unet_June_25_BIG_model.keras\n",
      "Cluster model loaded from: /hpc/aklicka/Python-data/training-set-1/June_25_BIG_model/cluster_model/unet_June_25_BIG_model_kmeans.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the trained autoencoder\n",
    "autoencoder_model = m.load_model(model_path, model_name=model_name)\n",
    "\n",
    "#Â Load a previously saved cluster model from disk\n",
    "cluster_model = m.load_cluster_model(cluster_model_path, model_name=cluster_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11be9d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size_blob = 3000 #maximum pixel area of a blob to keep in the image\n",
    "area_threshold = 50 #minimum pixel area of a blob to keep in the image\n",
    "feature_size = 16 #radius of feature window taken from the centroid of the blob, actual window size is 2*feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 files with extension 'npy' in directory:\n",
      "/hpc/aklicka/Python-data/training-set-1/June_25_BIG_model/windows/predict\n",
      "Found 64 files with extension '.txt' in directory:\n",
      "/hpc/aklicka/Python-data/training-set-1/June_25_BIG_model/windows/predict\n"
     ]
    }
   ],
   "source": [
    "step1_predict_files, step1_num_predict = dp.list_files_by_extension(windows_predict_path, 'npy')\n",
    "\n",
    "# Get the corresponding image coordimages list file\n",
    "step1_prediction_windows_coordinates_file_list , _ = dp.list_files_by_extension(windows_predict_path,'.txt',verbose=False)\n",
    "step1_prediction_windows_coordinates_file_list = [\n",
    "    name for name in step1_prediction_windows_coordinates_file_list \n",
    "    if \"coordinates\" in name\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ebb421",
   "metadata": {},
   "source": [
    "### Only run next code window if you do not have the feature windows already saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1eaac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No target folders found to delete.\n",
      "Prediction file: /hpc/aklicka/Python-data/training-set-1/June_25_BIG_model/windows/predict/default_2011Feb11-105510_STM-STM_Spectroscopy--110_16_BD/default_2011Feb11-105510_STM-STM_Spectroscopy--110_16_BD_all_windows.npy\n",
      "Coords file: /hpc/aklicka/Python-data/training-set-1/June_25_BIG_model/windows/predict/default_2011Feb11-105510_STM-STM_Spectroscopy--110_16_BD/default_2011Feb11-105510_STM-STM_Spectroscopy--110_16_BD_coordinates.txt\n",
      "\n",
      "---\n",
      "Processing file default_2011Feb11-105510_STM-STM_Spectroscopy--110_16_BD_all_windows.npy\n",
      "Not shuffling\n",
      "Data pipeline created with 1 files, batch size: 32768, window size: 32\n",
      "Sample batch shape: (32768, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "dp.delete_data_folders(job_data_path, subdirectories=[\"step2/windows/predict\"], override=True)\n",
    "\n",
    "\n",
    "for image_num in range(len(step1_predict_files)):\n",
    "    prediction_file = step1_predict_files[image_num]  \n",
    "    coords_file = step1_prediction_windows_coordinates_file_list[image_num]  \n",
    "\n",
    "    print(\"Prediction file:\", prediction_file)\n",
    "    print(\"Coords file:\", coords_file)\n",
    "    print(\"Prediction file shape:\", np.load(prediction_file).shape)\n",
    "    #print(\"Coords file shape:\", np.loadtxt(coords_file).shape)\n",
    "        \n",
    "    #get reconstructed image and cluster image\n",
    "    reconstructed_img, cluster_img = m.reconstruct_predict(prediction_file, coords_file, autoencoder_model, cluster_model, window_size, predictions_batch_size)\n",
    "\n",
    "    # Detect features and find centers\n",
    "    #labeled_array, centers, num_features = m.detect_features_better(cluster_img, max_size=max_size_blob, area_threshold=area_threshold)\n",
    "    #features, centers, labeled_array, num_features = m.detect_features_find_centres(cluster_img, max_size=70000, area_threshold=64,)\n",
    "    centers = m.detect_centers(cluster_img, min_size=350)\n",
    "\n",
    "\n",
    "    #extract feature windows from the reconstructed image\n",
    "    feature_windows = m.extract_feature_windows(reconstructed_img, centers, px=feature_size)\n",
    "\n",
    "    image_name = os.path.splitext(os.path.basename(prediction_file))[0]\n",
    "    # Save the feature windows to disk for each reconstructed image\n",
    "    dp.save_feature_windows_together(feature_windows, centers, step2_windows_predict_path, base_filename=image_name, verbose=True)\n",
    "\n",
    "    #save / display the reconstructed and cluster images with centers highlighted\n",
    "    #m.display_reconstructed_and_cluster_images_and_extracted_features(reconstructed_img, cluster_img, labeled_array, centers,\n",
    "    #                                                                 save_to_disk=True, output_path=feature_predictions_path, image_name=image_name, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f438cd8",
   "metadata": {},
   "source": [
    "### Step 2: Cluster Feature windows. Display labeled features.\n",
    "\n",
    "Step 2 only uses windows cut around the found features in the image. The latent vectors for step 2 are related to the 'feature' windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data - tensorflow data pipeline of feature window images\n",
    "step2_predict_files, step2_num_predict = dp.list_files_by_extension(step2_windows_predict_path, 'npy')\n",
    "\n",
    "#for image_num in range(len(predict_files)):\n",
    "image_num = 2\n",
    "\n",
    "#create a dataset for each image\n",
    "step2_predict_dataset = m.create_tf_dataset_batched(\n",
    "    step2_predict_files[image_num:image_num+1],  # Use only one file for predictions\n",
    "    batch_size=predictions_batch_size, \n",
    "    #buffer_size=cluster_buffer_size, \n",
    "    window_size=feature_size*2,  # feature windows are 2*feature_size\n",
    "    is_autoencoder=True, \n",
    "    shuffle=False)\n",
    "\n",
    "dp.delete_data_folders(job_data_path, subdirectories=[\"step2/latent_features/predict\"], override=True)\n",
    "\n",
    "#create latent features for each image\n",
    "m.extract_latent_features_to_disk_from_prebatched_windows(\n",
    "    autoencoder_model, \n",
    "    step2_predict_dataset, \n",
    "    step2_latent_features_predict_path, \n",
    "    bottleneck_layer_name='bottleneck',\n",
    "    features_name='step2_latent_features_predict',\n",
    "    return_array=False,\n",
    "    verbose=True)\n",
    "\n",
    "step2_predict_latent_features_files, step2_num_latent_files = dp.list_files_by_extension(step2_latent_features_predict_path, 'npy')\n",
    "\n",
    "# Load the latent features from disk into a tensor dataset pipeline\n",
    "step2_predict_latent_features_dataset = m.create_latent_features_tf_dataset(\n",
    "    step2_predict_latent_features_files,\n",
    "    batch_size=cluster_batch_size,\n",
    "    shuffle=False, \n",
    "    shuffle_buffer_size=cluster_buffer_size)\n",
    "\n",
    "#Â Load a previously saved cluster model from disk\n",
    "step2_cluster_model = m.load_cluster_model(step2_cluster_model_path, model_name=cluster_model_name)\n",
    "step2_cluster_model_spectral = m.load_cluster_model(step2_cluster_model_path, model_name=cluster_model_spectral_name)\n",
    "\n",
    "\n",
    "# load latent features as a numpy array with shape (num features, latent vector lenght)\n",
    "data = np.load(step2_predict_latent_features_files[0])\n",
    "\n",
    "# use cluster model to predict labels for each feature window. shape (num features,)\n",
    "#labels = step2_cluster_model.predict(data)\n",
    "labels = step2_cluster_model_spectral.fit_predict(data)\n",
    "\n",
    "# loads the image windows. Shape (num features, 32, 32)\n",
    "image = np.load(step2_predict_files[image_num])\n",
    "\n",
    "# Sort the labels numerically, while also sorting the corresponding feature windows\n",
    "sorted_indices = np.argsort(labels)\n",
    "sorted_labels = labels[sorted_indices]\n",
    "sorted_feature_windows = image[sorted_indices]\n",
    "# Display the first 64 images in a 8x8 grid along with their labels\n",
    "def display_images_with_labels(images, labels, num_images=64):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(10, 10, i + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='viridis')\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "display_images_with_labels(sorted_feature_windows, sorted_labels, num_images=image.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c051e43",
   "metadata": {},
   "source": [
    "#### Display reconstructed image with features circled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ef041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get reconstructed image and cluster image\n",
    "reconstructed_img, cluster_img = m.reconstruct_predict(predict_files[image_num], prediction_windows_coordinates_file_list[image_num], autoencoder_model, cluster_model, window_size, predictions_batch_size)\n",
    "\n",
    "# Get the corresponding image coordimages list file\n",
    "step2_prediction_windows_coordinates_file_list , _ = dp.list_files_by_extension(step2_windows_predict_path,'.txt',verbose=False)\n",
    "\n",
    "# Get the coordinates for a specific image with index `image_num`\n",
    "coordinates_data = np.loadtxt(step2_prediction_windows_coordinates_file_list[image_num], skiprows=1, dtype=float).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the tab10 colormap as an array\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "colormap = [ \"orange\", \"tab:pink\", \"tab:red\", \"tab:green\", \"yellow\", \"purple\",  \"tab:cyan\", \"tab:blue\", \"darkred\", \"blue\"]\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "patches = []\n",
    "label_names = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.imshow(reconstructed_img, cmap=\"gray\")\n",
    "\n",
    "for number in unique_labels:\n",
    "    indexes = [i for i, val in enumerate(labels) if val == number]\n",
    "    for index in indexes:\n",
    "        y, x = coordinates_data[index]\n",
    "        r = plt.Rectangle((x-16, y-16),width = 32, height = 32, color = colormap[number], linewidth=1.05, fill = False)\n",
    "        ax.add_patch(r)\n",
    "    \n",
    "    # Add a patch for the legend (only once per label)\n",
    "    patch = mpatches.Patch(color=colormap[number], label=f\"Label {number}\")\n",
    "    patches.append(patch)\n",
    "    label_names.append(f\"Label {number}\")\n",
    "\n",
    "ax.legend(handles=patches, labels=label_names, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c16c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_predictions_files, num_jpg_predict = dp.list_files_by_extension(predictions_path, 'jpg')\n",
    "#display a jpg prediction with index jpg_predictions_files[0]\n",
    "jpg_prediction_file = jpg_predictions_files[image_num]\n",
    "jpg_prediction = ski.io.imread(jpg_prediction_file)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(jpg_prediction, cmap='viridis')\n",
    "plt.title(f'Prediction: {os.path.basename(jpg_prediction_file)}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d93767",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from math import sqrt\n",
    "\n",
    "image_gray = cluster_img.astype(float)\n",
    "blobs_log = blob_log(image_gray, max_sigma=30, num_sigma=10, threshold=0.1)\n",
    "print(\"Number of blobs detected using LoG:\", len(blobs_log))\n",
    "# Compute radii in the 3rd column.\n",
    "blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=0.1)\n",
    "blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "print(\"Number of blobs detected using DoG:\", len(blobs_dog))\n",
    "\n",
    "blobs_doh = blob_doh(image_gray, max_sigma=30, threshold=0.01)\n",
    "print\n",
    "blobs_list = [blobs_log, blobs_dog, blobs_doh]\n",
    "colors = ['yellow', 'lime', 'red']\n",
    "titles = ['Laplacian of Gaussian', 'Difference of Gaussian', 'Determinant of Hessian']\n",
    "sequence = zip(blobs_list, colors, titles)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "for idx, (blobs, color, title) in enumerate(sequence):\n",
    "    ax[idx].set_title(title)\n",
    "    ax[idx].imshow(cluster_img, interpolation='nearest')\n",
    "    for blob in blobs:\n",
    "        y, x, r = blob\n",
    "        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
    "        ax[idx].add_patch(c)\n",
    "    ax[idx].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gray = cluster_img.astype(float)\n",
    "image_gray = np.expand_dims(image_gray, axis=-1)  # Now shape is (900, 900, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1cf000",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_dog = blob_log(image_gray, max_sigma=30, threshold=0.1)\n",
    "blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "print(\"Number of blobs detected using DoG:\", len(blobs_dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blobs_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43501102",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))  # Adjust figsize (width, height) as desired\n",
    "color = 'red'  # Color for the circles\n",
    "ax.set_title('Blobs Detected using DoG')\n",
    "ax.imshow(cluster_img, interpolation='nearest')\n",
    "for blob in blobs_dog:\n",
    "    y, x, z, r = blob\n",
    "    c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
    "    ax.add_patch(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
